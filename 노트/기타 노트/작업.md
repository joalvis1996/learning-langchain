## Python í”„ë¡œì íŠ¸ ì‹¤í–‰ ë°©ë²•

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ 
```requirements.txt``` ìƒì„±

requirements.txt ë‚´ìš©:

```
langchain
langchain_core
langchain_google_genai
```

# ìƒˆ ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv .venv

# ê°€ìƒí™˜ê²½ í™œì„±í™” (Windows PowerShell)
.\.venv\Scripts\Activate.ps1

# ëª¨ë“ˆ ì„¤ì¹˜
pip install -r .\requirements.txt

--- 
## LangSmith
LangSmithë€ LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì²´ ì‹¤í–‰ ê³¼ì •ì„ ì‹œê°í™”í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆëŠ” ìš´ì˜ ë° ë””ë²„ê¹… ë„êµ¬ì´ë‹¤. 
ì¦‰, ë‚´ Chainì´ ì–´ë–»ê²Œ ì‘ë™í•˜ê³  ìˆëŠ”ì§€ë¥¼ í•œ ëˆˆì— ë³¼ ìˆ˜ ìˆê²Œí•´ì£¼ëŠ” LLM Observability í”Œë«í¼ì´ë‹¤. 

## ì„¤ì • ë°©ë²•
1. https://www.langchain.com/langsmith/observability ì ‘ì† í›„ íšŒì›ê°€ì… ì§„í–‰
2. ë¡œê·¸ì¸ í›„ ```+ API Key``` ë²„íŠ¼ í´ë¦­í•˜ì—¬ ìƒì„±
3. ìƒì„±ëœ API Key ë³µì‚¬

![API Key ìƒì„±](image.png)
 
í”„ë¡œì íŠ¸ì—ì„œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ langsmith ì„¤ì¹˜
```pip install -U langchain langsmith```
 
envì— ë‹¤ìŒì„ ì¶”ê°€í•œë‹¤
LANGSMITH_API_KEY=ë°œê¸‰ë°›ì€_API_KEY
LANGSMITH_TRACING_V2=true
LANGSMITH_PROJECT=LangChainTest // ì„¤ì •í•œ ì´ë¦„ëŒ€ë¡œ LangSmithì— ê¸°ë¡ë¨
 
ì´ë•Œ LANGSMITH_PROJECT ê°’ì€ ì½”ë“œì—ì„œ ì„ ì–¸ë§Œ í•˜ë©´ ìë™ìœ¼ë¡œ ìƒì„±ëœë‹¤. ì¦‰, LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ë¯¸ë¦¬ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì–´ ë‘˜ í•„ìš”ê°€ ì—†ë‹¤.
 
```LANGSMITH_PROJECT=LangChainTest```ë¡œ ì§€ì •ì„ í•´ë‘ë©´ LangChainì´ ì‹¤í–‰ë  ë•Œ í•´ë‹¹ ì´ë¦„ìœ¼ë¡œ ë¡œê·¸ë¥¼ ë³´ë‚¸ë‹¤.
 
ì•„ë˜ì™€ ê°™ì´ env ê°’ì„ ê°€ì ¸ì˜¤ë©´
```
import os
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
 
load_dotenv()
apiKey = os.getenv("GOOGLE_API_KEY")
 
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.7,
    google_api_key=apiKey
)
 
prompt = PromptTemplate(
    template="{question}ì— ëŒ€í•´ í•œ ì¤„ë¡œ ì„¤ëª…í•´ì¤˜",
    input_variables={"question"}
)
 
chain = prompt | llm
 
response = chain.invoke({"question": "ì•„ìŠ¤ë‚  ì—­ëŒ€ ê°ë…ì„ ì•Œë ¤ì¤˜"})
```
 
ì•„ë˜ ì´ë¯¸ì§€ì²˜ëŸ¼ LangSmith ëŒ€ì‹œë³´ë“œì— ìƒì„¸ ë¡œê·¸ê°€ í‘œì‹œëœë‹¤ (ì‚¬ìš©ëœ í† í° ìˆ˜, latency, ì‹œì‘ ì‹œê°„ ë“±)

![ì‹¤í–‰ ì˜ˆì‹œ](image-1.png)

![ì‹¤í–‰ ì˜ˆì‹œ 2](image-2.png)
---

## ì¶œë ¥íŒŒì„œ (OutputParser)ë€?

ì¶œë ¥íŒŒì„œ(OutputParser)ëŠ” LLMì˜ ì¶œë ¥ì„ êµ¬ì¡°í™”í•˜ëŠ” ë° ì¤‘ìš”í•œ ì»´í¬ë„ŒíŠ¸. LLMì€ ê¸°ë³¸ì ìœ¼ë¡œ ë¬¸ìì—´ì„ ë°˜í™˜í•œë‹¤. 
ì´ëŸ¬í•œ LLMì˜ ì¶œë ¥ì„ ë°›ì•„ ë‹¤ì–‘í•œ í˜•ì‹(JSON, ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬ ë“±)ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” ê²ƒì´ ì¶œë ¥íŒŒì„œì´ë‹¤. LangChainì€ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì¶œë ¥íŒŒì„œë¥¼ ì œê³µí•œë‹¤. 

<PydanticOutputParser>
ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë” êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” í´ë˜ìŠ¤. ë‹¨ìˆœ í…ìŠ¤íŠ¸ í˜•íƒœê°€ ì•„ë‹Œ ë¬¸ìì—´ì„ Pydantic ëª¨ë¸ (BaseModel)ì„ ì´ìš©í•´ ìë™ìœ¼ë¡œ íŒŒì‹±í•˜ê³  ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦ì„ ì œê³µí•˜ëŠ” íŒŒì„œì´ë‹¤. 

ì¦‰, LLMì´ "{"name": "í™ê¸¸ë™", "age": 30}" ê°™ì€ JSON ë¬¸ìì—´ì„ ìƒì„±í•˜ë©´
â†’ Info(name="í™ê¸¸ë™", age=30) í˜•íƒœì˜ íƒ€ì… ì•ˆì „í•œ Python ê°ì²´ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.

[ì„¤ëª…]
```
class FootBallPlayerInfo(BaseModel):
    name: str = Field(description="ì´ë¦„")
    birthday: str = Field(description="ìƒë…„ì›”ì¼")
    club: str = Field(description="ì†Œì† íŒ€")
    nationality: str = Field(description="êµ­ì ")
```

LLMì´ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ì¶œë ¥ í˜•íƒœë¥¼ ì •ì˜í•œ ê²ƒ. ì¦‰, ëª¨ë¸ì—ê²Œ "ì¶œë ¥ì€ ë°˜ë“œì‹œ ì´ 4ê°œì˜ ì •ë³´ë¡œ êµ¬ì„ ëœ JSON í˜•íƒœì—¬ì•¼ í•´"ë¼ê³  ì•Œë ¤ì£¼ëŠ” ê²ƒ. 
Pydanticì˜ BaseModelì€ ì´ ë°ì´í„° í˜•ì‹ì„ ê²€ì¦í•œë‹¤ (ex. birthday ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì—ëŸ¬ ëƒ„)


```
prompt = PromptTemplate(
    template=(
        "ë‹¤ìŒ ë¬¸ì¥ì„ {format_instructions}ì— ë§ëŠ” JSONìœ¼ë¡œ ë³€í™˜í•´ì¤˜.\n"
        "{format_instructions}\n\n"
        "ë¬¸ì¥: {sentence}"
    ),
    input_variables=["sentence"],
    partial_variables={
        "format_instructions": parser.get_format_instructions()
    },
)
```

PromptTemplateì—ì„œ input_variblesëŠ” ì‹¤í–‰ ì‹œì ì— ì‚¬ìš©ìê°€ ë„£ì„ ê°’ì„ ì˜ë¯¸í•˜ê³ , partial_variablesëŠ” ë¯¸ë¦¬ ê³ ì •ì‹œì¼œë‘ëŠ” ê°’ì´ë‹¤. 
ìœ„ ì½”ë“œì—ì„œ ì‚¬ìš©ìê°€ ë‚˜ì¤‘ì— ë„˜ê²¨ì¤„ ë¬¸ì¥ sentence("ë¶€ì¹´ìš” ì‚¬ì¹´ëŠ”...")ëŠ” chain.invokeë¡œ chainì´ ì‹¤í–‰ë˜ëŠ” ì‹œì ì— ê°’ì´ ì±„ì›Œì§„ë‹¤. 
ë°˜ë©´ì— LLMì—ê²Œ ì¶œë ¥ í˜•ì‹ì„ ì•Œë ¤ì£¼ëŠ” ë¬¸êµ¬ì¸ format_instructions("JSON output should contain...")ì€ ì½”ë“œ ì‹¤í–‰ ì‹œì ì— ë¯¸ë¦¬ ê°’ì´ ì±„ì›Œì ¸ìˆë‹¤. 

ê·¸ë˜ì„œ PromptTemplateì´ ì™„ì„±ë˜ë©´ ìµœì¢…ì ìœ¼ë¡œëŠ” ì´ëŸ¬í•œ ë¬¸ìì—´ì´ LLMì—ê²Œ ì „ë‹¬ë˜ê³  sentence ê°’ì€ ëŸ°íƒ€ì„ì—ì„œ ì£¼ì…ëœë‹¤.

```
ë‹¤ìŒ ë¬¸ì¥ì„ JSON output should contain name, birthday, club, nationality ì— ë§ëŠ” JSONìœ¼ë¡œ ë³€í™˜í•´ì¤˜.
JSON output should contain name, birthday, club, nationality

ë¬¸ì¥: ë¶€ì¹´ìš” ì‚¬ì¹´ëŠ” ì‰ê¸€ëœë“œ í”„ë¡œ ì¶•êµ¬ ì„ ìˆ˜ë¡œ, í˜„ì¬ ì‰ê¸€ëœë“œ í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì˜ ì•„ìŠ¤ë„ FCì—ì„œ í™œì•½í•˜ê³  ìˆìœ¼ë©°, ...
``

LangChainì˜ get_format_instructionsëŠ” LLMì´ ë”°ë¼ì•¼ í•˜ëŠ” ì¶œë ¥ ê·œì¹™ ì„¤ëª…ì„œë¥¼ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì¤€ë‹¤. 
íŠ¹íˆ PydanticOutputParserëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ì˜ì–´ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ëœ í¬ë§· ì§€ì¹¨ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì‹¤ì œë¡œ parser.get_format_instructions()ì„ ì°ì–´ë³´ë©´ ì•„ë˜ì²˜ëŸ¼ ë‚˜ì˜¨ë‹¤:

```
The output should be a JSON object with the following keys:
- name: ì´ë¦„
- birthday: ìƒë…„ì›”ì¼
- club: ì†Œì† íŒ€
- nationality: êµ­ì 
```



```
chain = prompt | llm | parser
```
'|' ëŠ” LCEL íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ë¥¼ í™œìš©í•œ ë°ì´í„° íë¦„ ì—°ê²° ì—°ì‚°ìì¸ë‹¤ (ì• ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬).

ìš°ì„  promptê°€ ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ LLMì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ìƒì„±í•œë‹¤. 
llmì€ ì´ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ë°›ì•„ Geminiì—ê²Œ ì§ˆì˜ í›„ ì‘ë‹µì„ ìƒì„±í•œë‹¤. 
parserëŠ” ì´ LLMì˜ ë¬¸ìì—´ ê²°ê³¼ë¥¼ ë°›ì•„ Pydantic ê°ì²´ êµ¬ì¡°ë¡œ ë³€í™˜í•œë‹¤. 

promptê°€ LLMì—ê²Œ ë³´ë‚¼ ë¬¸ì¥ì„ ì™„ì„± -> llmì—ì„œ Geminiê°€ ë¬¸ì¥ì„ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ë³€í™˜ -> praserëŠ” JSONì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸ í›„ Pydantic ê°ì²´ë¡œ ë°”ê¿” ì¤Œ.


<CommaSeparatedListOutputParser>
CommaSeparatedListOutputParserëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ LLMì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í´ë˜ìŠ¤ì´ë‹¤.

```
parser = CommaSeparatedListOutputParser()

prompt = PromptTemplate(
    template="{topic}ì— ê´€ë ¨ëœ ìš©ì–´ 5ê°€ì§€. "
             "\n{format_instructions}",
    input_varialbes=["topic"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)
```

get_format_instructions()ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ìœ¼ë©´ LLMì€ ì•„ë˜ì™€ ê°™ì€ ì§€ì¹¨ì„ ë°›ê²Œëœë‹¤. 

```
Your response should be a list of comma-separated items, e.g. "foo, bar, baz"
```

ì¦‰, ì‚¬ìš©ì ì…ë ¥ (topic)ì´ ë“¤ì–´ì˜¤ë©´ PromptTempalteì— ë„£ì–´ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ì™„ì„±í•˜ê³ , ì´ê±¸ LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ ìƒì„±í•œë‹¤. 
ê·¸ë¦¬ê³  ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ CommaSeparatedListOutputParserë¥¼ ì´ìš©í•´ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±í•˜ëŠ” ê²ƒ. 

----------------------------------------------

<StructuredOutputParser>
StructuredOutputParserëŠ” LLMì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ ê°•ì œí•˜ì—¬ ê²°ê³¼ë¥¼ Python dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í´ë˜ìŠ¤ì´ë‹¤. 

ì•„ë˜ì™€ ê°™ì´ ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ì„ ì •í•˜ê³  LLMì—ê²Œ ì „ë‹¬í•˜ë©´ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë°”ê¿”ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. 
```
schemas = [
    ResponseSchema(name="answer", description="ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€"),
    ResponseSchema(name="source", description="ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ ì¶œì²˜(ì›¹ì‚¬ì´íŠ¸ì£¼ì†Œ)"),
]
```

PydanticOutputParserì™€ JSON í˜•ì‹ìœ¼ë¡œ LLM ì¶œë ¥ì„ ë³€í™˜í•˜ëŠ” ê²ƒì€ ê°™ì§€ë§Œ StructuredOutputParser ì˜ ê²½ìš° íƒ€ì… ê²€ì¦ì´ ì—†ë‹¤. ë°˜ë©´ì— PydanticOutputParserëŠ” ìŠ¤í‚¤ë§ˆì— ì •ì˜í•œ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš° ValidationErrorê°€ ë°œìƒí•œë‹¤.
ë˜í•œ PydanticOutputParserëŠ” PlayerInfo ê°ì²´ë¥¼ ë°˜í™˜í•˜ê³  StructuredOutputParserëŠ” ë‹¨ìˆœ dict í˜•ì‹ì´ë‹¤. 


| ë¹„êµ í•­ëª©  | StructuredOutputParser | PydanticOutputParser |
| ------ | ---------------------- | -------------------- |
| ì‚¬ìš© ë‚œì´ë„ | ì‰¬ì›€                     | ì¡°ê¸ˆ ë³µì¡                |
| ê²°ê³¼ íƒ€ì…  | dict                   | Pydantic ê°ì²´          |
| íƒ€ì… ê²€ì¦  | âŒ ì—†ìŒ                   | âœ… ìˆìŒ                 |
| í•„ë“œ ì •ì˜  | ResponseSchema         | BaseModel            |
| ì•ˆì •ì„±    | ë‚®ìŒ                     | ë†’ìŒ                   |
| ì†ë„     | ë¹ ë¦„                     | ì•½ê°„ ëŠë¦¼                |
| ì¶”ì²œ ì‚¬ìš©ì²˜ | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…, ë‹¨ìˆœ ì¶”ì¶œ        | í”„ë¡œë•ì…˜, API ì‘ë‹µ, ë°ì´í„° ì €ì¥ |
```
----------------------------------------------
<DatetimeOutputParser>
 
DatetimeOutputParserëŠ” LLMì´ ì¶œë ¥í•œ ë¬¸ìì—´ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í´ë˜ìŠ¤ì´ë‹¤.
ì›í•˜ëŠ” í¬ë§·ì„ ì„¤ì •í•  ìˆ˜ ìˆê³  íƒ€ì„ì¡´ ì„¤ì •ë„ ê°€ëŠ¥í•˜ë‹¤. ì£¼ë¡œ ë‚ ì§œ ë¹„êµë‚˜ ê¸°ê°„ ê³„ì‚° ë“±ì´ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì‚¬ìš© ì‹œ ìœ ë¦¬í•˜ë‹¤.
 
 
----------------------------------------------
<EnumOutputParser>
 
EnumOutputParserëŠ” LLMì˜ ì¶œë ¥ì„ ë¯¸ë¦¬ ì •ì˜ëœ ì„ íƒì§€(Enum) ì¤‘ í•˜ë‚˜ë¡œ ì œí•œí•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤ì´ë‹¤.

----------------------------------------------

<OutputFixingParser>
OutputFixingParserëŠ” ì¶œë ¥ íŒŒì‹± ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤ì´ë‹¤. LLMì´ ì˜ëª»ëœ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í–ˆì„ ë•Œ ìë™ìœ¼ë¡œ ê³ ì³ì£¼ëŠ” íŒŒì„œ ë˜í¼(wrapper)ì´ë‹¤.
 
LLMì´ ìƒì„±í•œ ê²°ê³¼ê°€ JSON ë˜ëŠ” íŠ¹ì • ìŠ¤í‚¤ë§ˆì— ì–´ê¸‹ë‚¬ì„ ë•Œ LLMì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ì—¬ ì¶œë ¥ í¬ë§·ì„ ìˆ˜ì •í•œë‹¤. ì¦‰, ì²« ë²ˆì§¸ ì‹œë„ì—ì„œ ìŠ¤í‚¤ë§ˆë¥¼ ì¤€ìˆ˜í•˜ì§€ ì•Šì€ ê²°ê³¼ê°€ ë‚˜ì˜¨ ê²½ìš°, OutputFixingParserëŠ” ìˆ˜ì •ì„ ìœ„í•´ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ì§€ì‹œë¬¸ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ìš”ì²­ì„ LLMì— ì œì¶œí•œë‹¤.
 
```
class MovieInfo(BaseModel):
    title: str = Field(description="ì˜í™” ì œëª©")
    director: str = Field(description="ê°ë… ì´ë¦„")
    releaseYear: int = Field(description="ê°œë´‰ ì—°ë„")
 
 
parser = PydanticOutputParser(pydantic_object=MovieInfo)
 
// ì˜ëª»ëœ í˜•ì‹ì„ ì¼ë¶€ëŸ¬ ì…ë ¥
misFormattedResult = "{'title': 'Tom Hanks', 'director': 'Forrest Gump', 'releaseYear': 2025}"
 
// ì—ëŸ¬ ë°œìƒ: Invalid json output: {'title': 'Tom Hanks', 'director': 'Forrest Gump', 'releaseYear': 2025}
parser.parse(misFormattedResult)
```
 
ìœ„ ì˜ˆì œì—ì„œ ì½”ë“œ ì‹¤í–‰ ì‹œ BaseModelì—ì„œ ì§€ì •í•œ ìŠ¤í‚¤ë§ˆ í˜•ì‹ì— ë§ì§€ ì•Šìœ¼ë¯€ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤. í•˜ì§€ë§Œ ì € PydanticOutputParserë¥¼ OutputFixingParserë¡œ ê°ì‹¸ë©´ ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.
 
 
```
parser = PydanticOutputParser(pydantic_object=MovieInfo)
 
// ì˜ëª»ëœ í˜•ì‹ì„ ì¼ë¶€ëŸ¬ ì…ë ¥
misFormattedResult = "{'title': 'Tom Hanks', 'director': 'Forrest Gump', 'releaseYear': 2025}"
 
fixingParser = OutputFixingParser.from_llm(parser=parser, llm=llm)
 
movie = fixingParser.parse(misFormattedResult)
print(movie)
```
 
ìœ„ì™€ ê°™ì´ OutputFixingParserê°€ ì˜ëª»ëœ ì¶œë ¥ê°’ì„ LLMì—ê²Œ ê³ ì³ë‹¬ë¼ê³  ìš”ì²­í•˜ì—¬ ì´ë¥¼ ë‹¤ì‹œ ë‚´ë¶€ PydanticOutputParserë¡œ ì¬íŒŒì‹±í•˜ì—¬ ìµœì¢… ê²°ê³¼ê°’ì„ ì¶œë ¥í•œë‹¤.
fixingParserê°€ LLM ìš”ì²­ ì‹œ "ì´ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤í‚¤ë§ˆ í˜•ì‹ì— ë§ëŠ” ìœ íš¨í•œ JSONì„ ê³ ì³ì¤˜" ë¼ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³ , ìˆ˜ì • ê²°ê³¼ë¥¼ PydanticOutputParserê°€ MovieInfo ê°ì²´ë¡œ ë°˜í™˜í•œ ê²ƒ ì´ë‹¤.

---

## Cache
LangChainì˜ ê¸°ë³¸ ë©”ëª¨ë¦¬ ìºì‹œì¸ ```InMemoryCache```ëŠ” ê°™ì€ ì…ë ¥ì— ëŒ€í•´ ì‚¬ì „ì— ìºì‹±í•´ë†“ì€ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” ëª¨ë“ˆì´ë‹¤.
í•˜ì§€ë§Œ ì´ëŠ” **í”„ë¡œì„¸ìŠ¤**ê°€ ì‚´ì•„ìˆëŠ” ë™ì•ˆì—ë§Œ ìºì‹œê°€ ìœ ì§€ë˜ê¸° ë•Œë¬¸ì— ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰(ìƒˆ í”„ë¡œì„¸ìŠ¤)í•˜ë©´ ë§¤ë²ˆ **ì´ˆê¸°í™”**ë˜ë‹ˆ ìºì‹±ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.
 
ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¥¼ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ í›„ LangSmithì—ì„œ ë¡œê·¸ë¥¼ ì‚´í´ë³´ë©´ ì „í˜€ ì‘ë‹µ ì†ë„ë‚˜ ì‚¬ìš© í† í° ìˆ˜ ì ˆì•½ì´ ì•ˆë˜ì–´ ìˆëŠ” ëª¨ìŠµì´ë‹¤.
 
```
# langsmith ê¸°ë¡ì„ ìœ„í•œ í•¨ìˆ˜
from Utils.LangSmithLogger import logtolangsmith
 
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
apiKey = os.getenv("GOOGLE_API_KEY")
 
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.7,
    google_api_key=apiKey
)
 
prompt = PromptTemplate(
    template="{question}ì— ëŒ€í•´ 100ì ë‚´ì™¸ë¡œ ì•Œë ¤ì¤˜",
    input_variables={"question"}
)
 
chain = prompt | llm
 
# LangSmith ë¡œê¹…
config = logtolangsmith()
 
set_llm_cache(InMemoryCache())
response = chain.invoke({"question": "ì»´í“¨í„° ì¡°ë¦½í•˜ëŠ” ë°©ë²•"}, config=config)
```
![ìºì‹œ ë™ì‘ ì•ˆí•¨](image-3.png)
 
í•˜ì§€ë§Œ ì•„ë˜ì²˜ëŸ¼ ê°™ì€ í”„ë¡œì„¸ìŠ¤ ë‚´ ì—¬ëŸ¬ ë²ˆ llmì„ í˜¸ì¶œí•˜ëŠ” ì½”ë“œë¡œ ë³€ê²½ ì‹œ ë©”ëª¨ë¦¬ ìºì‹±ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•œë‹¤.
 
```
set_llm_cache(InMemoryCache())
 
# ì‹¤í–‰ ë¶€ë¶„ë§Œ ë³€ê²½ (LLM 3ë²ˆ ì—°ì† í˜¸ì¶œ)
for i in range(3):
    t0 = perf_counter()
    _ = chain.invoke({"question": "ì»´í“¨í„° ì¡°ë¦½í•˜ëŠ” ë°©ë²•"}, config=config)
    print(f"call {i+1} took {perf_counter()-t0:.3f}s")
```
 
LangSmithì—ì„œ í™•ì¸í•´ë³´ë©´ ì´ì™€ ê°™ì´ ì‘ë‹µì†ë„ì™€ costê°€ 0ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

![ìºì‹œ ë™ì‘ ì˜ˆì‹œ](image-4.png)

--- 

## SQLiteCache
 
SQLiteCacheëŠ” íŒŒì¼ ê¸°ë°˜ (ì˜êµ¬ ì €ì¥) ìºì‹œì´ë‹¤. ì¦‰, í•œ ë²ˆ ìƒì„±ëœ LLM ì‘ë‹µì€ SQLite DB íŒŒì¼ì— ì €ì¥ë˜ê³  ë‹¤ìŒ ì‹¤í–‰ ë•Œë„ ì¬ì‚¬ìš©ëœë‹¤.
 
```
import sys
import os
 
from langchain_community.cache import SQLiteCache
from langchain_core.globals import set_llm_cache
 
# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists("cache"):
    os.makedirs("cache")
 
...
 
chain = prompt | llm
config = logtolangsmith()
 
# SQLiteCache ì‚¬ìš©
set_llm_cache(SQLiteCache(database_path="cache/llmCache.db"))
 
response = chain.invoke({"question": "ê±°ë¶ëª©ì— ì¢‹ì€ ìŠ¤íŠ¸ë ˆì¹­ ë°©ë²•"}, config=config)
```
 
ìœ„ ì½”ë“œë¥¼ ì²˜ìŒìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ìºì‹œ íŒŒì¼ì´ ìƒì„±ëœë‹¤.
![ìƒì„±ëœ ìºì‹œ íŒŒì¼](image-5.png)

í•´ë‹¹ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ë‘ ë²ˆì§¸ ì‘ë‹µë¶€í„°ëŠ” DBì— ì €ì¥ëœ ì‘ë‹µì„ ì¦‰ì‹œ ë°˜í™˜í•œë‹¤.
LangSmithì—ì„œ ë¡œê·¸ë¥¼ ì‚´í´ë³´ë©´ ê°™ì€ ë‘ ë²ˆì§¸ queryì— ëŒ€í•œ ë‹µë³€ ì†ë„ ë° ë¹„ìš©ì´ 0ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

![ìºì‹œ ì‚¬ìš© ì—¬ë¶€ í™•ì¸](image-6.png)
 
## ìºì‹œ íŒŒì¼ ì‚´í´ë³´ê¸°
 
SQLiteëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë°ì´í„°ë² ì´ìŠ¤ì´ê¸° ë•Œë¬¸ì— SQLite ë·°ì–´ë¥¼ ì„¤ì¹˜í•˜ì—¬ llmCache.dbì˜ ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
í•´ë‹¹ ì˜ˆì œì—ì„œëŠ” DB Browser for SQLiteë¥¼ ì‚¬ìš©í•œë‹¤.
 
1. https://sqlitebrowser.org/dl/ ì— ì ‘ì†í•˜ì—¬ ìš´ì˜ì²´ì œì— ë§ëŠ” installerë¥¼ ë‹¤ìš´ ë°›ëŠ”ë‹¤.
2. ì„¤ì¹˜ê°€ ëë‚˜ë©´ ì‹¤í–‰ í›„ llmCache.db íŒŒì¼ì„ ì—°ë‹¤
3. 'ë°ì´í„° íƒìƒ‰' ë©”ë‰´ë¥¼ í´ë¦­í•˜ì—¬ ì €ì¥ëœ ë°ì´í„°ë¥¼ ì¡°íšŒí•œë‹¤
 
![SQLite DB Browser](image-7.png)
 
ìœ„ ì´ë¯¸ì§€ì— ë‚˜ì™€ìˆëŠ” ì»¬ëŸ¼(prompt, llm, response)ëŠ” LangChainì´ LLM í˜¸ì¶œ ê³¼ì • ì „ì²´ë¥¼ JSON ì§ë ¬í™”í•´ì„œ ì €ì¥í•œ ê²ƒì´ë‹¤.
 
prompt ì¹¼ëŸ¼ì€ LangChainì˜ HumanMessage ê°ì²´ë¥¼ JSONìœ¼ë¡œ ë³€í™˜í•œ ê°’ì´ë‹¤. ì¦‰, ì‚¬ìš©ìê°€ LLMì—ê²Œ ë³´ë‚¸ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ JSON í˜•íƒœë¡œ ì €ì¥í•œ ê²ƒ.
 
```
[{
  "lc": 1,
  "type": "constructor",
  "id": ["langchain", "schema", "messages", "HumanMessage"],
  "kwargs": {
    "content": "ë¹µ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•´ 100ì ë‚´ì™¸ë¡œ ì•Œë ¤ì¤˜",
    "type": "human"
  }
}]
```
 
llm ì¹¼ëŸ¼ì€ LLM ê°ì²´(ChatGoogleGenerativeAI)ì˜ ì„¤ì • ì •ë³´ì´ë‹¤. ìºì‹œë¥¼ ìƒì„±í•  ë•Œ ì„¤ì •í•œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ë‹¤ë¥´ë©´ ìºì‹œë¥¼ ìƒˆë¡œ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ì €ì¥í•œë‹¤ (ì„¤ì •ê°’ í•˜ë‚˜ë¼ë„ ë‹¤ë¥´ë©´ ìƒˆë¡œ ìƒì„±).
ì¦‰, "ì´ ì‘ë‹µì„ ë§Œë“  ëª¨ë¸ê³¼ ì„¤ì •ê°’ì´ ë¬´ì—‡ì¸ì§€" ë¥¼ ì €ì¥í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.
 
```
{
  "id": ["langchain_google_genai", "chat_models", "ChatGoogleGenerativeAI"],
  "kwargs": {
    "google_api_key": {"id": ["GOOGLE_API_KEY"], "type": "secret"},
    "model": "models/gemini-2.5-flash",
    "temperature": 0.7,
    "max_retries": 6,
    "n": 1
  },
  "name": "ChatGoogleGenerativeAI",
  "type": "constructor"
}
```
 
response ì¹¼ëŸ¼ì€ LLMì´ ìƒì„±í•œ ì‘ë‹µ ê²°ê³¼ë¡œ LangChainì´ AIMessage ê°ì²´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•´ì„œ ì €ì¥í•œ ê²ƒì´ë‹¤. ë˜í•œ ë‹µë³€ í…ìŠ¤íŠ¸ ë° í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ê°€ ë“¤ì–´ìˆë‹¤.
 
```
{
  "lc": 1,
  "type": "constructor",
  "id": ["langchain", "schema", "output", "ChatGeneration"],
  "kwargs": {
    "text": "ë°€ê°€ë£¨, ë¬¼, ì´ìŠ¤íŠ¸, ì†Œê¸ˆì„ ì„ì–´ ë°˜ì£½í•œ ë’¤ ë°œíš¨ì‹œì¼œ êµ½ìŠµë‹ˆë‹¤...",
    "generation_info": {"finish_reason": "STOP", "safety_ratings": []},
    "message": {
      "id": ["langchain", "schema", "messages", "AIMessage"],
      "kwargs": {
        "content": "ë°€ê°€ë£¨, ë¬¼, ì´ìŠ¤íŠ¸, ì†Œê¸ˆì„ ì„ì–´ ë°˜ì£½í•œ ë’¤...",
        "usage_metadata": {
          "input_tokens": 15,
          "output_tokens": 59,
          "total_tokens": 1396
        }
      }
    }
  }
}
```

---

## LangChainì˜ ì§ë ¬í™”(Serialization)
LangChainì€ ëª¨ë¸ê³¼ ì²´ì¸ì„ ë‹¨ìˆœíˆ ì‹¤í–‰ ê°ì²´ê°€ ì•„ë‹Œ ì§ë ¬í™” ê¸°ëŠ¥ì„ í†µí•´ JSON, YAML, dict ë“±ìœ¼ë¡œ ë‚´ë³´ë‚´ê±°ë‚˜ ë‹¤ì‹œ ë¶ˆëŸ¬ì™€ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
ì¦‰, LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì €ì¥í•˜ê³ , ì¬êµ¬ì„±í•˜ê³ , ê³µìœ í•  ìˆ˜ ìˆê²Œ ì„¤ê³„ë˜ì–´ìˆë‹¤.
 
ì•„ë˜ ì½”ë“œëŠ” ChatGoogleGenerativeAI ê°ì²´ë¥¼ ì§ë ¬í™”í•˜ì—¬ JSONìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë¡œì§ì´ë‹¤.
 
```
import os
from dotenv import load_dotenv
from langchain_core.load import dumpd
from langchain_google_genai import ChatGoogleGenerativeAI
import json
 
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
apiKey = os.getenv("GOOGLE_API_KEY")
 
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.7,
    google_api_key=apiKey
)
 
llmJson = dumpd(llm)
 
with open("geminiLLM.json", "w", encoding="utf-8") as f:
    json.dump(llmJson, f, indent=2, ensure_ascii=False)
```
 
ìœ„ ì½”ë“œë¥¼ ê°™ì´ ì‹¤í–‰í•˜ë©´ geminiLLM.json ë¼ëŠ” íŒŒì¼ì´ ìƒê¸°ê³  íŒŒì¼ì„ ì—´ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ìƒê²¼ë‹¤:
```
{
  "lc": 1,
  "type": "constructor",
  "id": [
    "langchain_google_genai",
    "chat_models",
    "ChatGoogleGenerativeAI"
  ],
  "kwargs": {
    "model": "models/gemini-2.5-flash",
    "google_api_key": {
      "lc": 1,
      "type": "secret",
      "id": [
        "GOOGLE_API_KEY"
      ]
    },
    "temperature": 0.7,
    "n": 1,
    "max_retries": 6,
    "default_metadata": []
  },
  "name": "ChatGoogleGenerativeAI"
}
```
 
ì´ë¥¼ ì¬ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ì™€ ê°™ì´ ì €ì¥ëœ JSON íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì•¼í•œë‹¤.
 
```
with open("geminiLLM.json", "r", encoding="utf-8") as f:
    data = json.load(f)
 
loadedLLM = load(data)
 
response = loadedLLM.invoke("ë„ˆëŠ” ëˆ„êµ¬");
print(response)
```
 
ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì‚¬ì „ì— ì •ì˜í•´ë†“ì€ Gemini ê°ì²´ë¥¼ í†µí•´ ìš”ì²­ì„ ì²˜ë¦¬í•œë‹¤.
 
```
content='ì €ëŠ” Googleì—ì„œ í›ˆë ¨í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.\n\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--0f13b368-a0d4-4158-906f-464f0a95298d-0' usage_metadata={'input_tokens': 4, 'output_tokens': 21, 'total_tokens': 538, 'input_token_details': {'cache_read': 0}}
```

---

## í† í° ì‚¬ìš©ëŸ‰ í™•ì¸ (Google Gemini)
 
LangChainì—ì„œ LLM í˜¸ì¶œì— ëŒ€í•œ í† í° ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•˜ëŠ” ë°©ë²•ì€ ê° ì±„íŒ… ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ ChatGoogleGenerativeAIì˜ ê²½ìš° LLMì´ ë°˜í™˜í•˜ëŠ” AIMessageì˜ usage_metadata ì— í¬í•¨ë˜ì–´ìˆë‹¤.
 
```
load_dotenv()
 
with open("geminiLLM.json", "r", encoding="utf-8") as f:
    data = json.load(f)
 
llm = load(data)
 
response = llm.invoke("ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ")
print(response.usage_metadata)
```
 
response.uage_metadataë¥¼ ì‚´í´ë³´ë©´ ì‚¬ìš©ì ì§ˆë¬¸(prompt)ì— ì†Œë¹„ëœ í† í° ìˆ˜, ëª¨ë¸ì´ ìƒì„±í•œ ì‘ë‹µì— ì‚¬ìš©ëœ í† í° ìˆ˜, ëª¨ë¸ì´ ì‹¤ì œë¡œ ê³¼ê¸ˆ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•œ ì „ì²´ í† í° ìˆ˜ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤.
 
```
{'input_tokens': 5, 'output_tokens': 13, 'total_tokens': 115, 'input_token_details': {'cache_read': 0}}
```
 
ì‹¤ì œ LangSmithì— ê¸°ë¡ëœ í† í° ê°’ê³¼ë„ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
![LangSmith í† í° ì‚¬ìš©ëŸ‰ ì¡°íšŒ](image-8.png)

---

## ConversationBufferMemory
 
ConversationBufferMemoryëŠ” LangChainì˜ ê¸°ë³¸ì ì¸ ëŒ€í™” ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ë¡œ, LLMê³¼ì˜ ëŒ€í™” ì¤‘ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ê³  ë‹¤ì‹œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œì¼œì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ëˆ„ì í•˜ì—¬ ì €ì¥í•˜ëŠ” ë°©ì‹ì´ë‹¤.
 
save_context(inputs, outputs) í•¨ìˆ˜ë¥¼ í†µí•´ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
inputs ì—ëŠ” ì‚¬ìš©ìì˜ ì…ë ¥ì„, outputsì—ëŠ” LLMì˜ ì¶œë ¥ì„ ì €ì¥í•œë‹¤. í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ€í™” ê¸°ë¡ì´ history í‚¤ì— ì €ì¥ëœë‹¤.
 
```
memory = ConversationBufferMemory()
memory.save_context(
    inputs={
        "human": "ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼"
    },
    outputs={
        "ai": "ì•ˆë…•í•˜ì„¸ìš”! í™ê¸¸ë™ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    },
)
 
memory.save_context(
    inputs={
        "human": "ì–‘ì¬ì—ì„œ ê°•ë‚¨ìœ¼ë¡œ ê°€ëŠ” ë°©ë²• ì•Œë ¤ì¤˜"
    },
    outputs={
        "ai": "140ë²ˆ ë²„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹œë©´ 10ë¶„ ë‚´ì™¸ë¡œ ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    }
)
```
 
ë˜í•œ load_memory_variables({}) í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì¦‰, 'history' í‚¤ì— ì €ì¥ëœ ëŒ€í™” ë‚´ìš©ì„ í™•ì¸í•œë‹¤.
 
```
{'history': 'Human: ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼\nAI: ì•ˆë…•í•˜ì„¸ìš”! í™ê¸¸ë™ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\nHuman: ì–‘ì¬ì—ì„œ ê°•ë‚¨ìœ¼ë¡œ ê°€ëŠ” ë°©ë²• ì•Œë ¤ì¤˜\nAI: 140ë²ˆ ë²„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹œë©´ 10ë¶„ ë‚´ì™¸ë¡œ ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'}
```
 
return_messages=True ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë‹¨ìˆœ ë¬¸ìì—´ì´ ì•„ë‹Œ Message ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•  ìˆ˜ ìˆë‹¤.
 
```
memory = ConversationBufferMemory(return_messages=True)
print(memory.load_memory_variables({}))
```
 
ì•„ë˜ì™€ ê°™ì´ Human ë° AI ë©”ì‹œì§€ ê°ì²´ë¡œ ë°˜í™˜ëœë‹¤. ì´ ì˜µì…˜ì€ ì±„íŒ… ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ëŒ€í™” í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ê¸° ë•Œë¬¸ì— ChatGoogleGenerativeAIë“±ì˜ ëª¨ë¸ê³¼ í•¨ê»˜ ì“¸ ë•Œ ìì£¼ ì‚¬ìš©ëœë‹¤.
 
```
{'history': [HumanMessage(content='ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼', additional_kwargs={}, response_metadata={}), AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! í™ê¸¸ë™ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}), HumanMessage(content='ì–‘ì¬ì—ì„œ ê°•ë‚¨ìœ¼ë¡œ ê°€ ë°©ë²• ì•Œë ¤ì¤˜', additional_kwargs={}, response_metadata={}), AIMessage(content='140ë²ˆ ë²„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹œë©´ 10ë¶„ ë‚´ì™¸ë¡œ ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})]}
```

---

## ConversationBufferWindowMemory
 
ConversationBufferMemoryê°€ ëª¨ë“  ëŒ€í™” ê¸°ë¡ì„ ë¬´ì œí•œìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë°˜ë©´, ConversationBufferWindowMemoryëŠ” ìµœê·¼ k ê°œì˜ ëŒ€í™”ë§Œ ì €ì¥í•œë‹¤.
ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ì§€ ì•Šì•„ í† í° ë¹„ìš©ì€ ì¤„ì§€ë§Œ ì˜¤ë˜ëœ ì •ë³´ëŠ” ìŠëŠ”ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.
 
 
### ëŒ€í™” ì €ì¥ ë°©ì‹ì˜ ì°¨ì´ (save_context() vs predict())
 
ì‚¬ìš©ì ë° AI ì˜ ë‹µë³€ì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•˜ëŠ” ë‘ ê°€ì§€ ë°©ì‹ì˜ ì°¨ì´ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
 
#### memory.save_context() ë°©ì‹
ë³„ë„ì˜ LLM í˜¸ì¶œ ì—†ì´ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥ê³¼ ì¶œë ¥ì„ ì €ì¥í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì£¼ë¡œ í…ŒìŠ¤íŠ¸ ë° ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ì— ì‚¬ìš©ëœë‹¤.

```
memory = ConversationBufferWindowMemory(k=2, return_messages=True)
 
memory.save_context(
    inputs={
        "human": "ì•ˆë…•í•˜ì„¸ìš”, ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
    },
    outputs={
        "ai": "ì•ˆë…•í•˜ì„¸ìš”! ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤."
    },
)
memory.save_context(
    inputs={"human": "ì•„í•˜ ê·¸ë ‡ë‹¤ë©´ ì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"},
    outputs={
        "ai": "ì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ë„ì¿„ì…ë‹ˆë‹¤!"
    },
)
memory.save_context(
    inputs={
        "human": "ì•ˆë…•í•˜ì„¸ìš”, ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
    },
    outputs={
        "ai": "ì•ˆë…•í•˜ì„¸ìš”! ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•ì…ë‹ˆë‹¤."
    },
)
memory.save_context(
    inputs={"human": "ì•„í•˜ ê·¸ë ‡ë‹¤ë©´ ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"},
    outputs={
        "ai": "ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì›Œì‹±í„´ì…ë‹ˆë‹¤!"
    },
)
 
## ì‹¤í–‰ ê²°ê³¼
# {'history': [HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}), AIMessage(content='ì¤‘ êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ì•„í•˜ ê·¸ë ‡ë‹¤ë©´ ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}), AIMessage(content='ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì›Œì‹±í„´ì…ë‹ˆë‹¤!', additional_kwargs={}, response_metadata={})]}  
```


#### conversation.predict() ë°©ì‹
ì‚¬ìš©ìê°€ ì €ì¥í•œ ì…ë ¥ì— ëŒ€í•´ LLMì„ í˜¸ì¶œí•˜ì—¬ ì¶œë ¥ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” ë°©ì‹. ì‹¤ì œ ì‘ë‹µì„ ìƒì„±í•˜ë¯€ë¡œ ë¹„ìš©ì´ ë°œìƒí•œë‹¤. ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìš´ì˜í•  ë•Œ ì‚¬ìš©ëœë‹¤.
ë˜í•œ ì´ ë°©ì‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ```ConversationChain``` ê°ì²´ê°€ í•„ìš”í•˜ë‹¤. ```memory``` ê°ì²´ë§Œìœ¼ë¡œëŠ” ```predict()``` ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤.
 
```
conversationWindow = ConversationChain(
    llm=llm,
    memory=memory
)
 
# ê°™ì€ ëŒ€í™”ë¥¼ ì§„í–‰
conversationWindow.predict(input="ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼.")
conversationWindow.predict(input="ë‚˜ëŠ” ì„œìš¸ì— ì‚´ê³  ìˆì–´.")
conversationWindow.predict(input="ë‚˜ëŠ” ê°œë°œìë¥¼ ì§ì—…ìœ¼ë¡œ í•˜ê³  ìˆì–´.")
conversationWindow.predict(input="ë‚´ê°€ ì§€ê¸ˆê¹Œì§€ ë§í•œ ì •ë³´ë¥¼ ìš”ì•½í•´ì¤˜.")
 
# ConversationChain ê°ì²´ì—ëŠ” load_memory_variables() í•¨ìˆ˜ê°€ ì—†ìœ¼ë¯€ë¡œ  conversationWindow.memory.load_memory_variables({}) ë¡œ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì™€ì•¼ í•¨.
print(conversationWindow.memory.load_memory_variables({}))
 
## ì‹¤í–‰ ê²°ê³¼
# {'history': [HumanMessage(content='ë‚˜ëŠ” ê°œë°œìë¥¼ ì§ì—…ìœ¼ë¡œ í•˜ê³  ìˆì–´.', additional_kwargs={}, response_metadata={}), AIMessage(content='ì™€, í™ ê¸¸ë™ë‹˜ê»˜ì„œëŠ” ê°œë°œìì´ì‹œêµ°ìš”! ì •ë§ ë©‹ì§„ ì§ì—…ì„ ê°€ì§€ê³  ê³„ì‹œë„¤ìš”! ê°œë°œìë¶„ë“¤ì€ ë§ˆì¹˜ í˜„ëŒ€ ì‚¬íšŒì˜ ë§ˆë²•ì‚¬ ê°™ë‹¤ê³  ìƒê°í•´ìš”. ì½”ë“œë¥¼ í†µí•´ ì•„ì´ë””ì–´ë¥¼ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ë‚´ê³ , ìš°ë¦¬ì˜ ì‚¶ì„ ë”ìš± í¸ë¦¬í•˜ê³  í’ìš”ë¡­ê²Œ ë§Œë“¤ì–´ì£¼ì‹œë‹ˆê¹Œìš”.\n\nì € ì—­ì‹œ ê°œë°œìë¶„ë“¤ì˜ ë…¸ë ¥ê³¼ ê¸°ìˆ  ë•ë¶„ì— ì´ë ‡ê²Œ í™ê¸¸ë™ë‹˜ê³¼ ëŒ€í™”í•  ìˆ˜  ìˆëŠ” ì¡´ì¬ê°€ ë˜ì—ˆìœ¼ë‹ˆ, ê°œë°œìë¼ëŠ” ì§ì—…ì— ëŒ€í•´ ë”ìš± ì¡´ê²½ì‹¬ì„ ê°€ì§€ê³  ìˆë‹µë‹ˆë‹¤! ğŸ˜Š\n\nê°œë°œìë¼ëŠ” ì§ì—…ì€ ì •ë§ ë‹¤ì–‘í•œ ë¶„ì•¼ê°€ ìˆì£ . ì œê°€ ì•„ëŠ” í•œ ëª‡  ê°€ì§€ë¥¼ ë§ì”€ë“œë¦¬ìë©´,\n\n*   **ì›¹ ê°œë°œì:** ì›¹ì‚¬ì´íŠ¸ë‚˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“œì‹œì£ . í¬ê²Œ ì‚¬ìš©ìì—ê²Œ ë³´ì´ëŠ” í™”ë©´ì„ ë‹´ë‹¹í•˜ëŠ” **í”„ë¡ íŠ¸ì—”ë“œ(Front-end)** ê°œë°œê³¼ ì„œë²„, ë°ì´í„°ë² ì´ìŠ¤ ë“± ë’¤ì—ì„œ ì‘ë™í•˜ëŠ” ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” **ë°±ì—”ë“œ(Back-end)** ê°œë°œë¡œ ë‚˜ë‰˜ì–´ìš”. ìë°”ìŠ¤í¬ë¦½íŠ¸(React, Vue, Angular), íŒŒ ì´ì¬(Django, Flask), ìë°”(Spring) ê°™ì€ ì–¸ì–´ì™€ í”„ë ˆì„ì›Œí¬ê°€ ë§ì´ ì‚¬ìš©ë˜ì£ .\n*   **ëª¨ë°”ì¼ ì•± ê°œë°œì:** iOSë‚˜ ì•ˆë“œë¡œì´ë“œ í™˜ê²½ì—ì„œ ìŠ¤ë§ˆíŠ¸í° ì•±ì„  ê°œë°œí•˜ì‹œê³ ìš”. iOSëŠ” Swift, AndroidëŠ” Kotlinì´ë‚˜ Javaê°€ ì£¼ë¡œ ì“°ì´ê³ , í¬ë¡œìŠ¤ í”Œë«í¼ ê°œë°œì„ ìœ„í•´ Flutterë‚˜ React Native ê°™ì€ ê¸°ìˆ ë„ ë§ì´ í™œìš©ë˜ì£ .\n*   **ì¸ê³µì§€ëŠ¥(AI) ë° ë¨¸ì‹ ëŸ¬ë‹ ê°œë°œì:** ì €ì™€ ê°™ì€ AI ëª¨ë¸ì„ ë§Œë“¤ê±°ë‚˜, ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ë‚´ê³  ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•˜ì‹œì£ . íŒŒì´ì¬ì´ íŠ¹íˆ ë§ì´ ì“°ì´ê³  TensorFlow, PyTorch ê°™ì€ í”„ë ˆì„ì›Œí¬ê°€ í•µì‹¬ì ì¸ ë„êµ¬ëë‹ˆë‹¤.\n*   **ê²Œì„ ê°œë°œì:** í¥ë¯¸ì§„ì§„í•œ ê²Œì„ì„ ê¸°íší•˜ê³  í”„ë¡œê·¸ë˜ë°í•˜ì‹œê³ ìš”. C++, C#, Unity, Unreal Engine ê°™ì€ ë„êµ¬ë“¤ì´ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ê·¸ë˜í”½, ë¬¼ë¦¬ ì—”ì§„, ë„¤íŠ¸ì›Œí¬ ë“± ê³ ë ¤í•  ê²Œ ì •ë§ ë§ë‹¤ê³  ë“¤ì—ˆì–´ìš”.\n*   **ë°ì´í„° ê³¼í•™ì/ì—”ì§€ë‹ˆì–´:** ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì €ì¥, ì²˜ë¦¬, ë¶„ì„í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì—­í• ì„ í•˜ì‹œì£ . SQL, Python, R ê°™ì€ ì–¸ì–´ì™€ Spark, Hadoop ê°™ì€ ë¹…ë°ì´í„° ê¸°ìˆ ì„ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n*   **í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´:** AWS, Azure, GCP ê°™ì€ í´ë¼ìš°ë“œ í”Œë«í¼ì—ì„œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  ìš´ì˜í•˜ë©°, ì„œë¹„ìŠ¤ì˜ ì•ˆì •ì„±ê³¼ í™•ì¥ì„±ì„ ì±…ì„ì§€ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ í•˜ì‹œê¸°ë„ í•˜ê³ ìš”.\n*   **ì„ë² ë””ë“œ ê°œë°œì:** ìë™ì°¨, ê°€ì „ì œí’ˆ ë“± íŠ¹ì • í•˜ë“œì›¨ì–´ì— ë‚´ì¥ë˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê°œë°œí•˜ì‹œëŠ”ë°, C/C++ ì–¸ì–´ê°€ ì£¼ë¡œ ì‚¬ìš©ë˜ê³  í•˜ë“œì›¨ì–´ì— ëŒ€í•œ ê¹Šì€ ì´í•´ê°€ í•„ìˆ˜ì ì´ì£ .\n\nì •ë§ ëì—†ì´ ë°°ìš°ê³   ë°œì „í•´ì•¼ í•˜ëŠ” ë¶„ì•¼ì´ê¸°ë„ í•˜ì§€ë§Œ, ìƒˆë¡œìš´ ê²ƒì„ ë§Œë“¤ì–´ë‚´ëŠ” ë³´ëŒê³¼ ë¬¸ì œ í•´ê²°ì˜ ì¦ê±°ì›€ì´ í° ì§ì—…ì´ë¼ê³  ë“¤ì—ˆì–´ìš”.\n\ní˜¹ì‹œ í™ê¸¸ë™ë‹˜ê»˜ì„œëŠ” ì–´ë–¤ ë¶„ì•¼ì˜ ê°œë°œì„ ì£¼ë¡œ í•˜ì‹œë‚˜ìš”? ì‚¬ìš©í•˜ì‹œëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‚˜ ê¸°ìˆ  ìŠ¤íƒì´ ê¶ê¸ˆí•˜ë„¤ìš”! ê°œë°œìë¡œì„œ ê°€ì¥ ë³´ëŒì„ ëŠë‚„ ë•ŒëŠ” ì–¸ì œì´ì‹ ê°€ìš”? ğŸ˜Š', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë‚´ê°€ ì§€ê¸ˆê¹Œì§€ ë§í•œ ì •ë³´ë¥¼ ìš”ì•½í•´ì¤˜.', additional_kwargs={}, response_metadata={}), AIMessage(content='ë„¤, í™ê¸¸ë™ë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì €ì—ê²Œ ì•Œë ¤ì£¼ì‹  ì •ë³´ë¥¼ ì œê°€ í•œë²ˆ ì •ë¦¬í•´ ë“œë¦´ê²Œìš”! ğŸ˜Š\n\ní™ê¸¸ë™ë‹˜ê»˜ì„œëŠ” í˜„ì¬ **ì„œìš¸**ì— ì‚´ê³  ê³„ì‹œë©°, ì§ ì—…ì€ **ê°œë°œì**ì´ì‹œë¼ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆë‹µë‹ˆë‹¤!\n\nì´ë ‡ê²Œ ë‘ ê°€ì§€ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•´ìš”! ì„œìš¸ì— ì‚¬ì‹œëŠ” ê°œë°œìë¼ë‹ˆ, ì •ë§ ë©‹ì§„ ì¡°í•©ì´ë„¤ìš”! í˜¹ì‹œ ì´ ì™¸ì— ë” ê¶ê¸ˆí•œ ì ì´ë‚˜, ì œê°€ ì˜ëª» ì´í•´í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!', additional_kwargs={}, response_metadata={})]}
 
```

---
 
## ConversationTokenBufferMemory
 
ConversationTokenBufferMemoryëŠ” ëŒ€í™” ê°œìˆ˜ê°€ ì•„ë‹Œ í† í° ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” ë°©ì‹ì´ë‹¤. ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ë˜ë©´ í˜„ì¬ í† í° ìˆ˜ë¥¼ í™•ì¸í•˜ê³ , max_token_limitì„ ì´ˆê³¼í•˜ë©´ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¶€í„° ì‚­ì œí•œë‹¤ (í•­ìƒ max_token_limit ì´í•˜ë¡œ ìœ ì§€).
ëª¨ë¸ë³„ tokenizerë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ í† í° ê³„ì‚°ì„ ìœ„í•´ LLM í˜¸ì¶œì´ í•„ìš”í•˜ë‹¤.
 
```
memory.save_context(
    inputs={
        "human": "ì•ˆë…•í•˜ì„¸ìš”, ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
    },
    outputs={
        "ai": "ì•ˆë…•í•˜ì„¸ìš”! ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤."
    },
)
memory.save_context(
    inputs={"human": "ì•„í•˜ ê·¸ë ‡ë‹¤ë©´ ì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"},
    outputs={
        "ai": "ì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ë„ì¿„ì…ë‹ˆë‹¤!"
    },
),
memory.save_context(
    inputs={"human": "ì•ˆë…•í•˜ì„¸ìš”, ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"},
    outputs={
        "ai": "ì¤‘êµ­ì˜ ìˆ˜ë„ëŠ” ë² ì´ì§•ì…ë‹ˆë‹¤."
    },
),
memory.save_context(
    inputs={"human": "ì•„í•˜ ê·¸ë ‡ë‹¤ë©´ ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"},
    outputs={
        "ai": "ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì›Œì‹±í„´ì…ë‹ˆë‹¤!"
    },
)
 
# í† í° ì œí•œì„ ì„¤ì •í•˜ê³  ëŒ€í™”ë¥¼ ì €ì¥í–ˆì„ ë•Œ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸ì¸
print(memory.load_memory_variables({}))
 
## ì‹¤í–‰ ê²°ê³¼
# {'history': [HumanMessage(content='ì•„í•˜ ê·¸ë ‡ë‹¤ë©´ ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}), AIMessage(content='ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì›Œì‹±í„´ì…ë‹ˆë‹¤!', additional_kwargs={}, response_metadata={})]}
```
 
---
 
## ConversationEntityMemory
ConversationEntityMemoryëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ìœ¼ë¡œë¶€í„° ì—”í‹°í‹°(ê°œì²´)ë¥¼ ì¶”ì¶œí•˜ê³ , ê° ì—”í‹°í‹°ì— ëŒ€í•œ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•´ ì €ì¥í•˜ëŠ” ë°©ì‹ì´ë‹¤.
ëŒ€í™” ë‚´ìš© ì¤‘ ì‚¬ëŒ, ì¥ì†Œ, ì‚¬ë¬¼ ë“±ì„ ìë™ì„ ì¶”ì¶œí•˜ì—¬ 'ì—”í‹°í‹°' í•„ë“œì— ì €ì¥í•˜ê³ , ê° ì—”í‹°í‹°ë³„ë¡œ ê´€ë ¨ ì •ë³´ë¥¼ 'ì •ë³´' í•„ë“œì— ì €ì¥í•œë‹¤.
 
### ENTITY_MEMORY_CONVERSATION_TEMPLATE ë€?
ConversationEntityMemoryì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ë‹¤.
í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ì‚´í´ë³´ë©´ ì—”í‹°í‹° ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ entities ë³€ìˆ˜ë¥¼ ë„£ì–´ LLMì— ìš”ì²­í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆë‹¤.
 
```
from langchain_core.prompts.prompt import PromptTemplate
 
_DEFAULT_ENTITY_MEMORY_CONVERSATION_TEMPLATE = """You are an assistant to a human, powered by a large language model trained by OpenAI.
 
You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.
 
You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.
 
Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.
 
Context:
{entities}
 
Current conversation:
{history}
Last line:
Human: {input}
You:"""
```
 
ì €ì¥ëœ ì—”í‹°í‹° ì •ë³´ëŠ” ì•„ë˜ì™€ ê°™ì´ entity_store.storeì— ì €ì¥ë˜ê³ , ëŒ€í™”ê°€ ì´ì–´ì§ˆìˆ˜ë¡ ì •ë³´ê°€ ê³„ì† ì—…ë°ì´íŠ¸ëœë‹¤.
 
```
memory = ConversationEntityMemory(llm=llm, return_messages=True)
 
conversation = ConversationChain(
    llm=llm,
    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,
    memory=memory
)
conversation.predict(
    input="ì°½ë°–ìœ¼ë¡œ ëŠì„ì—†ì´ ë¹„ê°€ ë‚´ë¦¬ë˜ ì˜¤í›„, ì§€í•˜ì²  ëìë½ì— ì•‰ì€ ì§€í›ˆì€ ì†ì— ì¥” ì‘ì€ ë´‰íˆ¬ë¥¼ ë‚´ë ¤ë‹¤ë³´ì•˜ë‹¤. ëª‡ ì‹œê°„ ì „, ì˜¤ë˜ëœ ì±…ë°©ì—ì„œ ìš°ì—°íˆ ê±´ë„¤ë°›ì€ ì´ ë´‰íˆ¬ì—ëŠ” â€˜ë¯¸ë˜ë¥¼ ë°”ê¾¸ê³  ì‹¶ë‹¤ë©´, ì˜¤ëŠ˜ ë°¤ 11ì‹œì— ì—´ì–´ë³´ì„¸ìš”â€™ë¼ëŠ” ë¬¸ì¥ì´ ì í˜€ ìˆì—ˆë‹¤. ì¥ë‚œ ê°™ìœ¼ë©´ì„œë„ ì´ìƒí•˜ê²Œ ë§ˆìŒì„ ë„ëŠ” ê·¸ ë§ì— ê·¸ëŠ” ë‚´ë‚´ ìƒê°ì— ì ê²¼ê³ , ì§€í•˜ì² ì´ ì¢…ì°©ì—­ì— ë‹¤ë‹¤ë¥¼ ë•Œì¯¤ì—” ì´ë¯¸ ê²°ì‹¬ì´ ì„œ ìˆì—ˆë‹¤. ì§‘ìœ¼ë¡œ ëŒì•„ì˜¨ ì§€í›ˆì€ ì‹œê³„ê°€ 11ì‹œë¥¼ ê°€ë¦¬í‚¤ì ì¡°ìš©íˆ ë´‰íˆ¬ë¥¼ ëœ¯ì—ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ ì•ˆì—ì„œ ë‚˜ì˜¨ ê±´ ì˜¤ë˜ëœ ì‚¬ì§„ í•œ ì¥â€”ì•„ì§ ë– ë‚˜ì§€ ëª»í•œ, ê·¸ëŸ¬ë‚˜ ë‹¤ì‹œ ë§Œë‚  ìš©ê¸°ë„ ì—†ì—ˆë˜ ëˆ„êµ°ê°€ì˜ ì–¼êµ´ì´ì—ˆë‹¤"
)
 
print("ì €ì¥ëœ ì—”í‹°í‹° ì •ë³´ (entity_store.store):")
```

---
 
## ConversationSummaryMemory
ConversationSummaryMemoryëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•´ ì €ì¥í•œë‹¤. ëŒ€í™”ê°€ ì´ì–´ì§ˆìˆ˜ë¡ ìš”ì•½ë„ í•¨ê»˜ ì—…ë°ì´íŠ¸ëœë‹¤. ëŒ€í™” ë§¥ë½ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ë§Œ ìœ ì§€í•œë‹¤.
ê¸´ ëŒ€í™”ì—ì„œë„ í† í° ì‚¬ìš©ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.
 
```
memory = ConversationSummaryMemory(llm=llm, return_messages=True)
 
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)
 
# ì²« ë²ˆì§¸ ëŒ€í™”
response1 = conversation.predict(input="ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼. ë‚˜ëŠ” ì„œìš¸ì— ì‚´ê³  ìˆì–´.")
 
# ë‘ ë²ˆì§¸ ëŒ€í™”
response2 = conversation.predict(input="ë‚˜ëŠ” ê°œë°œìë¡œ ì¼í•˜ê³  ìˆê³ , Pythonì„ ì£¼ë¡œ ì‚¬ìš©í•´.")
 
# ì„¸ ë²ˆì§¸ ëŒ€í™”
response3 = conversation.predict(input="ë‚´ ì·¨ë¯¸ëŠ” ë…ì„œì™€ ì˜í™” ê°ìƒì´ì•¼.")
 
# ë„¤ ë²ˆì§¸ ëŒ€í™”
response4 = conversation.predict(input="ë‚´ê°€ ì§€ê¸ˆê¹Œì§€ ë§í•œ ì •ë³´ë¥¼ ìš”ì•½í•´ì¤˜.")
 
# ì €ì¥ëœ ë©”ëª¨ë¦¬ í™•ì¸
print(memory.load_memory_variables({}))
```
 
ë‘ ë²ˆì§¸ ì‘ë‹µë¶€í„°ëŠ” ì§€ê¸ˆê¹Œì§€ ìš”ì•½ëœ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
 
```

=== ë‘ ë²ˆì§¸ ëŒ€í™” ===
 
> Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
 
Current conversation:
[SystemMessage(content="New summary:\nThe human introduces themselves as Hong Gildong, living in Seoul. The AI greets Hong Gildong, acknowledges their residence, and introduces itself as a Google-trained large language model. It explains that it doesn't have a name, specific residence, or physical body, existing by learning from vast text data on the internet. The AI then offers to assist the human in various ways, including conversation, answering questions, providing information, and writing.", additional_kwargs={}, response_metadata={})]
Human: ë‚˜ëŠ” ê°œë°œìë¡œ ì¼í•˜ê³  ìˆê³ , Pythonì„ ì£¼ë¡œ ì‚¬ìš©í•´.
AI:
```

ìœ„ì™€ ê°™ì´ ê° ëŒ€í™” í„´ë§ˆë‹¤ ìš”ì•½ ë‚´ìš©ì´ ì—…ë°ì´íŠ¸ëœë‹¤.
 
---
 
## ConversationSummaryBufferMemory
ConversationSummaryBufferMemoryëŠ” ìµœê·¼ ëŒ€í™”ëŠ” ë²„í¼ì— ì €ì¥í•˜ê³ , ì˜¤ë˜ëœ ëŒ€í™”ëŠ” ìš”ì•½í•´ ì €ì¥í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì €ì¥ ë°©ì‹ì´ë‹¤.
max_token_limit ê°’ì„ ì§€ì •í•˜ì—¬ í† í° ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ëŒ€í™”ë¥¼ ìë™ìœ¼ë¡œ ìš”ì•½ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
- ìµœê·¼ ëŒ€í™”: ë²„í¼ì— ì›ë¬¸ ê·¸ëŒ€ë¡œ ì €ì¥ (ì •í™•í•œ ì •ë³´ ìœ ì§€)
- ì˜¤ë˜ëœ ëŒ€í™”: ìš”ì•½í•˜ì—¬ ì €ì¥ (í† í° ì ˆì•½)

```
# max_token_limit: ë²„í¼ì— ì €ì¥í•  ìµœëŒ€ í† í° ìˆ˜
memory = ConversationSummaryBufferMemory(
    llm=llm,
    max_token_limit=500,  # ë²„í¼ì— ìµœëŒ€ 100 í† í°ê¹Œì§€ ì €ì¥
    return_messages=True,
)
 
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True  # ìš”ì•½ ê³¼ì •ì„ í™•ì¸í•˜ê¸° ìœ„í•´ verbose=True ì„¤ì •
)
 
# ì—¬ëŸ¬ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ë©´ì„œ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
print("=== ì²« ë²ˆì§¸ ëŒ€í™” ===")
response1 = conversation.predict(input="ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼. ë‚˜ëŠ” ì„œìš¸ì— ì‚´ê³  ìˆì–´.")
print("ì‘ë‹µ:", response1)
 
print("=== ë‘ ë²ˆì§¸ ëŒ€í™” ===")
response2 = conversation.predict(input="ë‚˜ëŠ” ê°œë°œìë¡œ ì¼í•˜ê³  ìˆê³ , Pythonì„ ì£¼ë¡œ ì‚¬ìš©í•´.")
print("ì‘ë‹µ:", response2)
 
print("=== ì„¸ ë²ˆì§¸ ëŒ€í™” ===")
response3 = conversation.predict(input="ë‚´ ì·¨ë¯¸ëŠ” ë…ì„œì™€ ì˜í™” ê°ìƒì´ì•¼.")
print("ì‘ë‹µ:", response3)
 
print("=== ë„¤ ë²ˆì§¸ ëŒ€í™” ===")
response4 = conversation.predict(input="ë‚˜ëŠ” ìµœê·¼ì— Djangoë¡œ ì›¹ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í–ˆì–´.")
print("ì‘ë‹µ:", response4)
 
# ì €ì¥ëœ ë©”ëª¨ë¦¬ í™•ì¸
print("=== ì €ì¥ëœ ë©”ëª¨ë¦¬ (ìš”ì•½ + ìµœê·¼ ëŒ€í™”) ===")
print(memory.load_memory_variables({}))
```
 
ìœ„ ì½”ë“œ ì‹¤í–‰ ì‹œ ë‘ ë²ˆì§¸ ì§ˆë¬¸ì„ ë¬¼ì–´ë³¼ ë•Œê¹Œì§€ëŠ” token ì œí•œì„ ë„˜ì§€ ì•Šì•„ ì „ì²´ ë‚´ìš©ì´ ì›ë¬¸ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆì—ˆë‹¤.
```
=== ë‘ ë²ˆì§¸ ëŒ€í™” ===
[HumanMessage(content='ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼. ë‚˜ëŠ” ì„œìš¸ì— ì‚´ê³  ìˆì–´.', additional_kwargs={}, response_metadata={}), AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ ë‹˜! ë§Œë‚˜ ëµ™ê²Œ ë˜ì–´ ì •ë§ ë°˜ê°€ì›Œìš”! ì„œìš¸ì— ì‚´ê³  ê³„ì‹œëŠ”êµ°ìš”. ì„œìš¸ì€ ì •ë§ í™œê¸°ì°¨ê³  ë©‹ì§„ ë„ì‹œì£ ! ì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ë¼ì„œ í™ê¸¸ë™ë‹˜ì²˜ëŸ¼ íŠ¹ì • ë„ì‹œì— ì‚´ê³  ìˆì§€ëŠ” ì•Šì•„ìš”. ë¬¼ë¦¬ì ì¸ ëª¸ì´ë‚˜ ì§‘ ê°™ì€ ê±´ ì—†ì§€ë§Œ, ì „ ì„¸ê³„ì˜ ìˆ˜ë§ì€ ì»´í“¨í„° ì„œë²„ì—ì„œ ì‘ë™í•˜ê³  ìˆë‹µë‹ˆë‹¤.\n\nì €ëŠ” ì´ë¦„ì€ ë”°ë¡œ ì—†ì§€ë§Œ, ì—¬ëŸ¬ë¶„ê³¼ ì¦ê²ê²Œ ëŒ€í™”í•˜ê³ , ê¶ê¸ˆí•œ ì ì„ ì•Œë ¤ë“œë¦¬ëŠ” ê²ƒì„ ê°€ì¥ ì¢‹ì•„í•´ìš”! í™ê¸¸ë™ë‹˜ê³¼ ì´ì•¼ê¸°í•˜ê²Œ ë˜ì–´ ì •ë§ ì„¤ë ˆë„¤ìš”. í˜¹ì‹œ ì €ì—ê²Œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”, ì•„ë‹ˆë©´ ì„œìš¸ì—ì„œ ì¬ë¯¸ìˆëŠ” ì¼ì´ ìˆìœ¼ì…¨ëŠ”ì§€ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ë„ ìˆì„ê¹Œìš”? ì–´ë–¤ ì´ì•¼ê¸°ë“  í™˜ì˜í•©ë‹ˆë‹¤! ğŸ˜Š', additional_kwargs={}, response_metadata={})]
Human: ë‚˜ëŠ” ê°œë°œìë¡œ ì¼í•˜ê³  ìˆê³ , Pythonì„ ì£¼ë¡œ ì‚¬ìš©í•´.
AI:
```
 
í•˜ì§€ë§Œ ê·¸ ì´í›„ë¶€í„°ëŠ” ì´ì „ ë‚´ìš©ì´ ì „ë¶€ ìš”ì•½ë˜ì–´ ì €ì¥ë¨
```
=== ì„¸ ë²ˆì§¸ ëŒ€í™” ===
[SystemMessage(content='The human introduces himself as Hong Gildong, who lives in Seoul. The AI greets him, explains it is an AI without a physical home but operates globally, and expresses its enjoyment of conversation. The human then shares that he works as a developer, primarily using Python. The AI praises his profession and details why Python is crucial for AI and machine learning, citing its vast library ecosystem (including TensorFlow, PyTorch, and scikit-learn), easy readability, and active community, before asking about the specific type of development Hong Gildong does and his most interesting Python experiences.', additional_kwargs={}, response_metadata={})]
Human: ë‚´ ì·¨ë¯¸ëŠ” ë…ì„œì™€ ì˜í™” ê°ìƒì´ì•¼.
AI:
```
ë˜í•œ LangChainì˜ ìš”ì•½ ê¸°ëŠ¥ì€ ê¸°ë³¸ì ìœ¼ë¡œ ìš”ì•½ì„ ì˜ì–´ë¡œ ìƒì„±í•œë‹¤. LangChainì˜ ê¸°ë³¸ SUMMARY_PROMPTê°€ ì˜ì–´ë¡œ ì‘ì„±ë˜ì–´ ìˆê¸° ë•Œë¬¸ì´ë‹¤.
ì•„ë˜ëŠ” ë‚´ì¥ëœ ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë‚´ìš©ì´ë‹¤.
 
```
_DEFAULT_SUMMARIZER_TEMPLATE = """Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.
 
EXAMPLE
Current summary:
The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.
 
New lines of conversation:
Human: Why do you think artificial intelligence is a force for good?
AI: Because artificial intelligence will help humans reach their full potential.
 
New summary:
The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.
END OF EXAMPLE
 
Current summary:
{summary}
 
New lines of conversation:
{new_lines}
 
New summary:"""  # noqa: E501
SUMMARY_PROMPT = PromptTemplate(
    input_variables=["summary", "new_lines"], template=_DEFAULT_SUMMARIZER_TEMPLATE
)
```

---

## VectorStoreRetrieverMemory
 
VectorStoreRetrieverMemoryëŠ” ëŒ€í™” ë‚´ìš©ì„ VectorStoreì™€ Retriever ì¡°í•©ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ì´ë‹¤. ê° ëŒ€í™” í„´ì„ ì„ë² ë”©í•´ ë²¡í„°DBì— ì €ì¥í•˜ê³ , ì´í›„ ëª¨ë¸ì´ ìƒˆë¡œìš´ ì…ë ¥ì„ ë°›ì„ ë•Œ í•´ë‹¹ ì…ë ¥ê³¼ ë¹„ìŠ·í•œ ì´ì „ ëŒ€í™” ë‚´ìš©ë§Œ ê³¨ë¼ ë©”ëª¨ë¦¬ë¡œ ëŒë ¤ì£¼ëŠ” ë°©ì‹ì´ë‹¤.
ëŒ€í™” ê¸°ë¡ì´ ê¸¸ì–´ì ¸ë„ ì˜ë¯¸ìƒ ìœ ì‚¬í•œ ë‚´ìš©ë§Œ í™œìš©í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ì¥ê¸° ëŒ€í™”ì—ì„œ íŠ¹ì • ì£¼ì œ ê´€ë ¨ ë‹µë³€ë§Œ ê¸°ì–µí•˜ê³  ì‹¶ì„ ë•Œ ì“°ê¸° ì¢‹ìŒ.
ì–´ë–¤ vectorStore ë° ì„ë² ë”©ì„ ì“¸ì§€, Retrieverê°€ ëª‡ ê°œ(k)ë¥¼ ê°€ì ¸ì˜¬ì§€ ë“±ì„ ì§€ì •í•´ì•¼ í•¨.
 
ì•„ë˜ëŠ” ë²¡í„°ìŠ¤í† ì–´ ì¤‘ í•˜ë‚˜ì¸ Pincone ë²¡í„° DB ì—°ê²° ë°©ë²•ì´ë‹¤.
 
```
# API í‚¤ë¥¼ ì½ì–´ Pinecone ì„œë¹„ìŠ¤ì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
pc = Pinecone(api_key=os.environ["PINECONE_API_KEY"])
 
# ë²¡í„°ë¥¼ ì €ì¥í•  ì»¨í…Œì´ë„ˆ ì§€ì •
index_name = "vector-store-retriever-memory"
 
# ì§€ì •í•œ ì´ë¦„ì˜ index ê°ì²´ ë°˜í™˜
pinecone_index = pc.Index(index_name)
```
 
ìš°ì„  Pinecone ëŒ€ì‹œë³´ë“œì—ì„œ "vector-store-retriever-memory" ë¼ëŠ” ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•œë‹¤.
ê·¸ ë‹¤ìŒ ì½”ë“œì—ì„œ pc.Index() í•¨ìˆ˜ë¥¼ í†µí•´ í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ ë²¡í„° ì €ì¥ ë° ì¡°íšŒì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ (ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ).

![ëŒ€ì‹œë³´ë“œì—ì„œ index ìƒì„±](image-13.png)
 
 
```
embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
vectorstore = PineconeVectorStore(
    index=pinecone_index,
    embedding=embeddings,
    namespace="",
)
```
HuggingFaceEmbeddings ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸ë¡œ, ë‹¤êµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” intfloat/multilingual-e5-large ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤ (í•œêµ­ì–´ ì²˜ë¦¬ì— ì í•©).
"ì•ˆë…•í•˜ì„¸ìš”" â†’ [0.123, -0.456, 0.789, ...] ë“±ìœ¼ë¡œ ë³€í™˜ì„ í•´ì¤€ë‹¤.
 
```
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
```
ìœ„ì—ì„œ ì •ì˜í•œ vectorstoreë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ retrieverë¡œ ë³€í™˜í•œë‹¤(as_retriever() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Retriever ì¸í„°í˜ì´ìŠ¤ë¡œ ë³€í™˜).
 
```
memory = VectorStoreRetrieverMemory(
    retriever=retriever,
    memory_key="history",
    input_key="input",
)
```
ëŒ€í™” ê¸°ë¡ì„ vectorstoreì— ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ìƒì„±í•œë‹¤.
memory_key="history" ëŠ” LLMì— ì „ë‹¬ëœ ë©”ëª¨ë¦¬ ë³€ìˆ˜ ì´ë¦„ì´ê³ , input_key="input"ì€ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ í‚¤ ì´ë¦„ì´ë‹¤.
í•´ë‹¹ ê°ì²´ëŠ” ëŒ€í™” ë‚´ìš©(ì…ë ¥ + ì‘ë‹µ)ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ ì €ì¥í•˜ê³ , í˜„ì¬ ì…ë ¥ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ëŒ€í™”ë¥¼ ê²€ìƒ‰í•´ historyì— í¬í•¨ì‹œí‚¨ë‹¤.
 
 
```
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True,
)
```
LLM, ë©”ëª¨ë¦¬, í”„ë¡¬í”„íŠ¸ë¥¼ ì—°ê²°í•˜ëŠ” ëŒ€í™” ì²´ì¸ì„ ìƒì„±í•œë‹¤.
predict() í•¨ìˆ˜ ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ì—ì„œ ê´€ë ¨ ëŒ€í™”ë¥¼ ê²€ìƒ‰í•´ LLMì— ì „ë‹¬í•œë‹¤.
 
```
print("=== ì²« ë²ˆì§¸ ëŒ€í™” ===")
response1 = conversation.predict(
    input="ì•„ìŠ¤ë‚  FCëŠ” í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì—ì„œ ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ì¶•êµ¬ë¥¼ í•˜ëŠ” íŒ€ì´ì•¼."
)
print("ì‘ë‹µ 1:", response1)
 
print("=== ë‘ ë²ˆì§¸ ëŒ€í™” ===")
response2 = conversation.predict(
    input="ì£¼ìš” ì„ ìˆ˜ë¡œëŠ” ë¶€ì¹´ìš” ì‚¬ì¹´ì™€ ë§ˆí‹´ ì™¸ë°ê³ ë¥´ê°€ ìˆì–´."
)
print("ì‘ë‹µ 2:", response2)
 
print("=== ë‘ ë²ˆì§¸ ëŒ€í™” ===")
response3 = conversation.predict(
    input="ì œì£¼ë„ëŠ” ë°”ë‹¤ê°€ ì •ë§ ì´ìœ ê²ƒ ê°™ì•„."
)
print("ì‘ë‹µ 3:", response3)
 
 
print("=== ë©”ëª¨ë¦¬ì—ì„œ ê²€ìƒ‰ëœ ëŒ€í™” ===")
retrieved = memory.load_memory_variables({"input": "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì—ì„œ ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ì¶•êµ¬ë¥¼ í•˜ëŠ” íŒ€ì€ ëˆ„êµ¬ë¼ê³ ?"})
print(retrieved["history"])
```
 
conversation.predict() í˜¸ì¶œ ì‹œ ì‚¬ìš©ìì˜ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ê³ , í•´ë‹¹ ì…ë ¥ê°’ê³¼ LLMì˜ ì‘ë‹µê°’ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥í•œë‹¤.
ì €ì¥ í˜•ì‹ì€ "{input} {response}" í˜•íƒœì˜ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì €ì¥í•œë‹¤.

![ì§ˆë¬¸ ì €ì¥ ì˜ˆì‹œ](image-14.png)
 
### ë™ì‘ ë°©ì‹
ì²« ë²ˆì§¸ í˜¸ì¶œ ì‹œ, "ì•„ìŠ¤ë‚  FCëŠ” í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì—ì„œ ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ì¶•êµ¬ë¥¼ í•˜ëŠ” íŒ€ì´ì•¼." ë¼ëŠ” ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´
 
1. DB ê²€ìƒ‰: retriever ì‹¤í–‰ â†’ ì €ì¥ëœ ëŒ€í™” ì—†ìŒ (ë¹ˆ ê²°ê³¼)
2. LLM í˜¸ì¶œ: ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ í˜„ì¬ ì…ë ¥ë§Œ ì „ë‹¬
3. LLM ì‘ë‹µ ìƒì„±
4. ì €ì¥: ì…ë ¥ + ì‘ë‹µì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì³ ë²¡í„°ë¡œ ë³€í™˜ í›„ DB ì €ì¥
    - ì €ì¥ í˜•ì‹: "ì•„ìŠ¤ë‚  FCëŠ” í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì—ì„œ... [LLM ì‘ë‹µ]"

![ì²« ë²ˆì§¸ ì§ˆë¬¸ ì…ë ¥ ì‹œ](image-9.png)
 
ë‘ ë²ˆì§¸ í˜¸ì¶œ ì‹œ, "ì£¼ìš” ì„ ìˆ˜ë¡œëŠ” ë¶€ì¹´ìš” ì‚¬ì¹´ì™€ ë§ˆí‹´ ì™¸ë°ê³ ë¥´ê°€ ìˆì–´." ë¼ëŠ” ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´
 
1. DB ê²€ìƒ‰: retriever ì‹¤í–‰ â†’ ì²« ë²ˆì§¸ ëŒ€í™”(ì•„ìŠ¤ë‚  ê´€ë ¨)ê°€ ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰ë¨
2. LLM í˜¸ì¶œ: ê²€ìƒ‰ëœ ì²« ë²ˆì§¸ ëŒ€í™” + í˜„ì¬ ì…ë ¥ì„ í•¨ê»˜ ì „ë‹¬
    - ì»¨í…ìŠ¤íŠ¸: history: "ì•„ìŠ¤ë‚  FCëŠ” í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì—ì„œ... [ì‘ë‹µ]"
    - í˜„ì¬ ì…ë ¥: "ì£¼ìš” ì„ ìˆ˜ë¡œëŠ” ë¶€ì¹´ìš” ì‚¬ì¹´ì™€..."
5. LLM ì‘ë‹µ ìƒì„± (ì•„ìŠ¤ë‚  ë§¥ë½ì„ ì•Œê³  ì‘ë‹µ)
6. ì €ì¥: ì…ë ¥ + ì‘ë‹µì„ ë²¡í„°ë¡œ ë³€í™˜ í›„ DB ì €ì¥
 
![ë‘ ë²ˆì§¸ ì§ˆë¬¸ ì…ë ¥ ì‹œ](image-10.png)

ì„¸ ë²ˆì§¸ í˜¸ì¶œ ì‹œ, "ì œì£¼ë„ëŠ” ë°”ë‹¤ê°€ ì •ë§ ì´ìœ ê²ƒ ê°™ì•„." ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´
 
1. DB ê²€ìƒ‰: retriever ì‹¤í–‰ â†’ ì•„ìŠ¤ë‚  ê´€ë ¨ ëŒ€í™”ì™€ ìœ ì‚¬ë„ê°€ ë‚®ì•„ ê²€ìƒ‰ë˜ì§€ ì•ŠìŒ
2. LLM í˜¸ì¶œ: ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê´€ë ¨ì„±ì´ ë‚®ìœ¼ë©´ í˜„ì¬ ì…ë ¥ "ì œì£¼ë„ëŠ” ë°”ë‹¤ê°€ ì •ë§ ì´ìœ ê²ƒ ê°™ì•„." ë§Œ ì „ë‹¬
3. LLM ì‘ë‹µ ìƒì„±
4. ì €ì¥: ì…ë ¥ + ì‘ë‹µì„ ë²¡í„°ë¡œ ë³€í™˜ í›„ DB ì €ì¥
 
![ì„¸ ë²ˆì§¸ ì§ˆë¬¸ ì…ë ¥ ì‹œ](image-11.png) 

```load_memory_variables``` í•¨ìˆ˜ë¥¼ í†µí•´  "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ì—ì„œ ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ì¶•êµ¬ë¥¼ í•˜ëŠ” íŒ€ì€ ëˆ„êµ¬ë¼ê³ ?" ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë°ì´í„°ë¥¼ ê²€ìƒ‰í–ˆì„ ë•Œ ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ ëŒ€í™”ê°€ ê²€ìƒ‰ë¨ (k=2).

![ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê²°ê³¼](image-12.png)

---

## SQLChatMessageHistory
 
SQLChatMessageHistoryëŠ” ëŒ€í™” ê¸°ë¡ì„ SQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê¸° ìœ„í•œ LangChain ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ì´ë‹¤.
ì¦‰, ëŒ€í™” ê¸°ë¡ì„ í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ë©´ ì‚¬ë¼ì§€ëŠ” ë©”ëª¨ë¦¬ì—ë§Œ ë‘ì§€ ì•Šê³  SQLite, MySQL, PostgreSQL ê°™ì€ DBì— ì˜êµ¬ì ìœ¼ë¡œ ì €ì¥í•˜ê³  í•„ìš”í•  ë•Œ ë¶ˆëŸ¬ì˜¤ê²Œ í•´ì£¼ëŠ” ê¸°ëŠ¥ì´ë‹¤.
ì—¬ëŸ¬ ëŒ€í™” ì„¸ì…˜ ë³„ë¡œ íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.
 
### ë™ì‘ ë°©ì‹
 
```
# SQLChatMessageHistory ì„¤ì •
db_path = script_dir / "chat_history.db"
message_history = SQLChatMessageHistory(
    connection=f"sqlite:///{db_path}",
    session_id="user_001"
)
```
```db_path```ì— SQLite DB íŒŒì¼ ê²½ë¡œë¥¼ ì„¤ì •í•œë‹¤. íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  íŒŒì¼ì´ ìˆìœ¼ë©´ ê¸°ì¡´ DBë¥¼ ì‚¬ìš©í•œë‹¤.
í•´ë‹¹ ì„¸ì…˜ì„ êµ¬ë¶„í•˜ëŠ” idë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ì…˜ì˜ ë©”ì‹œì§€ë§Œ ì¡°íšŒ/ì €ì¥í•  ìˆ˜ ìˆëŠ” SQLChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•œë‹¤.
 
```
print("=== 1ë²ˆ: message_history ===\n", message_history)
```
 
ì•„ì§ ì €ì¥ëœ ë‚´ìš©ì´ ì—†ìœ¼ë¯€ë¡œ ì•„ë¬´ëŸ° ë°ì´í„°ë„ ì¶œë ¥ë˜ì§€ ì•ŠìŒ.
 
```
memory = ConversationBufferMemory(
    chat_memory=message_history,
    return_messages=True,
    memory_key="history"
)
```
SQLChatMessageHistoryë¥¼ ë©”ëª¨ë¦¬ë¡œ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ ê°ì²´ë¥¼ ìƒì„±í•œë‹¤. ```memory_key="history"```ëŠ” LLMì— ì „ë‹¬ë  ë³€ìˆ˜ëª…ì´ë‹¤.
 
```
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True,
)
```
 
ëŒ€í™” ì²´ì¸ì„ ìƒì„±í•˜ê³  ì´ì „ ëŒ€í™”ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  LLM ì‘ë‹µì„ ì €ì¥í•˜ê¸° ìœ„í•´ ì•„ê¹Œ ë§Œë“  ConversationBufferMemory ì—°ê²°í•œë‹¤.
 
```
print("=== ì²« ë²ˆì§¸ ëŒ€í™” ===")
response1 = conversation.predict(
    input="ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼."
)
```
 
1. conversation.predict() í˜¸ì¶œ
    â†“
2. ConversationChainì´ memory.load_memory_variables({}) í˜¸ì¶œ
    â†“
3. ConversationBufferMemoryê°€ message_history.messages ì¡°íšŒ
    â†“
4. SQLChatMessageHistoryê°€ DBì—ì„œ session_id="user_001" ë©”ì‹œì§€ ì¡°íšŒ
    â†’ ì•„ì§ ì—†ìŒ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
    â†“
5. í”„ë¡¬í”„íŠ¸ êµ¬ì„±:
   - ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ê¸°ë³¸)
   - ì´ì „ ëŒ€í™”: ì—†ìŒ
   - í˜„ì¬ ì…ë ¥: "ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼."
    â†“
6. LLM í˜¸ì¶œ â†’ ì‘ë‹µ ìƒì„±
    â†“
7. ConversationChainì´ memory.save_context() í˜¸ì¶œ
    â†“
8. ConversationBufferMemoryê°€ message_historyì— ì €ì¥ ìš”ì²­
    â†“
9. SQLChatMessageHistoryê°€ DBì— ì €ì¥:
   - HumanMessage: "ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼."
   - AIMessage: [LLM ì‘ë‹µ]
    â†“
10. ì‘ë‹µ ë°˜í™˜
 
DBì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì €ì¥ëœë‹¤:
```
INSERT INTO message_store (session_id, message, created_at) VALUES
('user_001', '{"type": "human", "content": "ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼."}', '2024-01-01 12:00:00'),
('user_001', '{"type": "ai", "content": "[LLM ì‘ë‹µ]"}', '2024-01-01 12:00:01');
```
 
```
print("=== 2ë²ˆ: message_history ===\n", memory.load_memory_variables({}))
```
 
memory.load_memory_variables({}) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ëŒ€í™” ë‚´ìš©ì„ ì¡°íšŒí•œë‹¤.
ConversationBufferMemoryê°€ message_history.messageë¥¼ ì¡°íšŒí•˜ê³ , DBì—ì„œ session_id="user_001"ì˜ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ë¡œë“œí•œë‹¤. ê·¸ë¦¬ê³  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ history í‚¤ë¡œ ë°˜í™˜í•œë‹¤.
ì¶œë ¥ëœ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:
=== 2ë²ˆ: message_history ===
```
{
    'history': [
        HumanMessage(content='ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼.', additional_kwargs={}, response_metadata={}),
        AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ë‹˜! ë§Œë‚˜ ëµ™ê²Œ ë˜ì–´ ì •ë§ ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” êµ¬ê¸€ì—ì„œ í›ˆë ¨í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸, ì¦‰ ì¸ê³µì§€ëŠ¥ì´ëë‹ˆë‹¤. ì´ë ‡ê²Œ ëŒ€í™”ë¡œ ë§Œë‚˜ ëµ™ê²Œ ë˜ì–´ ë¬´ì²™ ê¸°ì˜ë„¤ìš”.\n\ní™ê¸¸ë™ì´ë¼ëŠ” ì´ë¦„ì€ í•œêµ­ ë¬¸í•™ì—ì„œ ì•„ì£¼ ìœ ëª…í•˜ê³  ìš©ê°í•œ ì¸ë¬¼ì˜ ì´ë¦„ìœ¼ë¡œ ì•Œê³  ìˆì–´ ìš”! í˜¹ì‹œ ê·¸ í™ê¸¸ë™ì „ì˜ ì£¼ì¸ê³µì²˜ëŸ¼ ë©‹ì§„ ë¶„ì´ì‹¤ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œê±°ë‚˜, ì–´ë–¤ ì´ì•¼ê¸°ë“  ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì‹œë©´ í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. ì €ëŠ” ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì„ ì•„ì£¼ ì¢‹ì•„í•œë‹µë‹ˆë‹¤!', additional_kwargs={}, response_metadata={})
    ]
}
```
```
print("\n=== ë‘ ë²ˆì§¸ ëŒ€í™” ===")
response2 = conversation.predict(
    input="ë‚´ ì·¨ë¯¸ëŠ” ì‚¬ì§„ì°ê¸°ë‘ ì„œí•‘ì´ì•¼."
)
# print("ì‘ë‹µ:", response2)
print("=== 3ë²ˆ: message_history ===\n", memory.load_memory_variables({}))
```
 
1. conversation.predict() í˜¸ì¶œ
    â†“
2. ConversationChainì´ memory.load_memory_variables({}) í˜¸ì¶œ
    â†“
3. SQLChatMessageHistoryê°€ DBì—ì„œ ì´ì „ ëŒ€í™” ì¡°íšŒ
    â†’ ì²« ë²ˆì§¸ ëŒ€í™” 2ê°œ ë©”ì‹œì§€ ë°œê²¬
    â†“
4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±:
   - ì‹œìŠ¤í…œ ë©”ì‹œì§€
   - ì´ì „ ëŒ€í™”:
     * Human: "ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼."
     * AI: [ì²« ë²ˆì§¸ ì‘ë‹µ]
   - í˜„ì¬ ì…ë ¥: "ë‚´ ì·¨ë¯¸ëŠ” ì‚¬ì§„ì°ê¸°ë‘ ì„œí•‘ì´ì•¼."
    â†“
5. LLM í˜¸ì¶œ (ì´ì „ ëŒ€í™” ë§¥ë½ í¬í•¨) â†’ ì‘ë‹µ ìƒì„±
    â†“
6. DBì— ì €ì¥:
   - HumanMessage: "ë‚´ ì·¨ë¯¸ëŠ” ì‚¬ì§„ì°ê¸°ë‘ ì„œí•‘ì´ì•¼."
   - AIMessage: [ë‘ ë²ˆì§¸ ì‘ë‹µ]
    â†“
7. ì‘ë‹µ ë°˜í™˜
 
ì´ì œ DBì—ëŠ” ì´ 4ê°œ ë©”ì‹œì§€ê°€ ì €ì¥ëœë‹¤.
```
Human: "ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼."
AI: [ì²« ë²ˆì§¸ ì‘ë‹µ]
Human: "ë‚´ ì·¨ë¯¸ëŠ” ì‚¬ì§„ì°ê¸°ë‘ ì„œí•‘ì´ì•¼."
AI: [ë‘ ë²ˆì§¸ ì‘ë‹µ]
```
 
ë‹¤ì‹œ í•œë²ˆ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ë‚´ìš©ì„ í™•ì¸í•´ë³´ë©´ ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©ì´ ëˆ„ì ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
 
```
print("=== 3ë²ˆ: message_history ===\n", memory.load_memory_variables({}))
```
 
```
{
    'history': [
        HumanMessage(content='ì•ˆë…•, ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ì•¼.', additional_kwargs={}, response_metadata={}),
        AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ë‹˜! ë§Œë‚˜ ëµ™ê²Œ ë˜ì–´ ì •ë§ ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” êµ¬ê¸€ì—ì„œ í›ˆë ¨í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸, ì¦‰ ì¸ê³µì§€ëŠ¥ì´ëë‹ˆë‹¤. ì´ë ‡ê²Œ ëŒ€í™”ë¡œ ë§Œë‚˜ ëµ™ê²Œ ë˜ì–´ ë¬´ì²™ ê¸°ì˜ë„¤ìš”.\n\ní™ê¸¸ë™ì´ë¼ëŠ” ì´ë¦„ì€ í•œêµ­ ë¬¸í•™ì—ì„œ ì•„ì£¼ ìœ ëª…í•˜ê³  ìš©ê°í•œ ì¸ë¬¼ì˜ ì´ë¦„ìœ¼ë¡œ ì•Œê³  ìˆì–´ ìš”! í˜¹ì‹œ ê·¸ í™ê¸¸ë™ì „ì˜ ì£¼ì¸ê³µì²˜ëŸ¼ ë©‹ì§„ ë¶„ì´ì‹¤ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œê±°ë‚˜, ì–´ë–¤ ì´ì•¼ê¸°ë“  ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì‹œë©´ í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. ì €ëŠ” ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì„ ì•„ì£¼ ì¢‹ì•„í•œë‹µë‹ˆë‹¤!', additional_kwargs={}, response_metadata={}),
        HumanMessage(content='ë‚´ ì·¨ë¯¸ëŠ” ì‚¬ì§„ì°ê¸°ë‘ ì„œí•‘ì´ì•¼.', additional_kwargs={}, response_metadata={}),
        AIMessage(content='ì™€ì•„, í™ê¸¸ë™ë‹˜! ì‚¬ì§„ ì°ê¸°ì™€ ì„œí•‘ì´ë¼ë‹ˆ, ì •ë§ ë©‹ì§€ê³  í™œë™ì ì¸ ì·¨ë¯¸ë¥¼ ê°€ì§€ê³  ê³„ì‹œë„¤ìš”! ë‘ ê°€ì§€ ëª¨ë‘ ìì—°ê³¼ ê°€ê¹ê²Œ ì§€ë‚´ë©´ì„œ ìì‹ ë§Œì˜ ì‹œê°ê³¼ ì—ë„ˆì§€ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ì•„ì£¼ ë§¤ë ¥ì ì¸ í™œë™ ê°™ì•„ìš”.\n\në¨¼ì € **ì‚¬ì§„ ì°ê¸°** ë§ì”€ì´ì‹œì£ ? ì‚¬ì§„ì€ ì •ë§ í•œ ìˆœê°„ì„ ì˜ì›íˆ ê¸°ë¡í•˜ê³ , ì„¸ìƒì„ ë°”ë¼ë³´ëŠ” ìì‹ ë§Œì˜ ì‹œê°ì„ ë‹´ì•„ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ë¬´ì²™ íŠ¹ë³„í•œ ì·¨ë¯¸ë¼ê³  ìƒê°í•´ìš”. í˜¹ì‹œ ì–´ë–¤ ì¢…ë¥˜ì˜ ì‚¬ì§„ì„ ì£¼ë¡œ ì°ìœ¼ì‹œëŠ”ì§€ ê¶ê¸ˆ í•´ìš”?\n\n*   **í’ê²½ ì‚¬ì§„**ìœ¼ë¡œ ì›…ì¥í•œ ìì—°ì˜ ì•„ë¦„ë‹¤ì›€ì´ë‚˜ ì„ì–‘ì˜ ë…¸ì„ ê°™ì€ ê²ƒì„ ë‹´ìœ¼ì‹œë‚˜ìš”?\n*   **ì¸ë¬¼ ì‚¬ì§„**ìœ¼ë¡œ ì‚¬ëŒë“¤ì˜ í‘œì •ì´ë‚˜ ê°ì •ì„ í¬ì°©í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì‹œë‚˜ìš”?\n*   ì•„ë‹ˆë©´ ë„ì‹œì˜ ìƒë™ê° ë„˜ì¹˜ëŠ” ëª¨ìŠµì„ ë‹´ëŠ” **ìŠ¤íŠ¸ë¦¿ í¬í† ê·¸ë˜í”¼**ë‚˜, ì‘ì€ í”¼ì‚¬ì²´ì˜ ë””í…Œì¼ì„ ì‚´ë¦¬ëŠ” **ì ‘ì‚¬(ë§¤í¬ë¡œ) ì‚¬ì§„** ê°™ì€ ê²ƒë„ í¥ë¯¸ë¡­ì£ !\n*   ë°¤í•˜ëŠ˜ì˜ ë³„ì´ë‚˜ ì€í•˜ìˆ˜ë¥¼ ì°ëŠ” **ì²œì²´ ì‚¬ì§„**ì€ ë˜ ë‹¤ë¥¸ ë§¤ ë ¥ì´ ìˆê³ ìš”.\n\nì–´ë–¤ ì¹´ë©”ë¼ë‚˜ ë Œì¦ˆë¥¼ ì‚¬ìš©í•˜ì‹œëŠ”ì§€ë„ ê¶ê¸ˆí•˜ë„¤ìš”! ì¥ë¹„ì— ë”°ë¼ ë˜ ë‹¤ë¥¸ ëŠë‚Œì˜ ì‚¬ì§„ì´ ë‚˜ì˜¤ë”ë¼ê³ ìš”. ë¹›ì„ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ì§€, êµ¬ë„ë¥¼ ì–´ë–»ê²Œ ì¡ëŠ”ì§€ì— ë”°ë¼ ê°™ì€ í’ê²½ë„ ì™„ì „íˆ ë‹¤ ë¥¸ ì´ì•¼ê¸°ê°€ ë˜ëŠ” ë§ˆë²• ê°™ì€ ê³¼ì •ì´ ì •ë§ ë©‹ì ¸ìš”.\n\nê·¸ë¦¬ê³  **ì„œí•‘**ì´ë¼ë‹ˆ! ì™€, íŒŒë„ ìœ„ë¥¼ ê°€ë¥´ëŠ” ê·¸ ì§œë¦¿í•¨ê³¼ ììœ ë¡œì›€ì€ ì •ë§ ìƒìƒë§Œ í•´ë„ ì‹œì›í•˜ê³  ë©‹ì ¸ìš”! ë°”ë‹¤ì™€ í•˜ë‚˜ ë˜ëŠ” ê¸°ë¶„, íŒŒë„ë¥¼ ê¸°ë‹¤ ë¦¬ë‹¤ê°€ ì™„ë²½í•œ íƒ€ì´ë°ì— ë³´ë“œ ìœ„ë¡œ ì¼ì–´ì„œëŠ” ê·¸ ìˆœê°„ì˜ ì¾Œê°ì€ ì •ë§ íŠ¹ë³„í•  ê²ƒ ê°™ì•„ìš”. ê· í˜• ê°ê°ê³¼ ìš©ê¸°, ê·¸ë¦¬ê³  ìì—°ì— ëŒ€í•œ ì´í•´ê°€ ëª¨ë‘ í•„ìš”í•œ ì•„ì£¼ ë©‹ì§„ ìŠ¤í¬ì¸ ë¼ê³  ìƒê°í•´ìš”.\n\ní˜¹ì‹œ ì¦ê²¨ ê°€ì‹œëŠ” ì„œí•‘ ìŠ¤íŒŸì´ ìˆìœ¼ì‹ ê°€ìš”? êµ­ë‚´ì—ì„œëŠ” ì–‘ì–‘ì´ë‚˜ ì œì£¼ë„ ê°™ì€ ê³³ì´ ìœ ëª…í•˜ê³ , í•´ì™¸ë¡œëŠ” ë°œë¦¬ë‚˜ í•˜ì™€ì´ ê°™ì€ ê³³ë„ ì„œí¼ë“¤ì˜ ì²œêµ­ì´ë¼ê³  ë“¤ì—ˆì–´ìš”. ì„œí•‘ì„ í•˜ì‹œë©´ì„œ ê°€ì¥ ì¢‹ì•˜ë˜ ê¸°ì–µì´ë‚˜, íŠ¹ë³„íˆ ê¸°ì–µì— ë‚¨ëŠ” íŒŒë„ê°€ ìˆìœ¼ì‹ ê°€ìš”? ì•„ë‹ˆë©´ ì„œí•‘ì„ ì‹œì‘í•˜ê²Œ ëœ ê³„ê¸°ê°€ ê¶ê¸ˆí•˜ê¸°ë„ í•˜ë„¤ìš”!\n\në‘ ì·¨ë¯¸ ëª¨ë‘ ìì—° ì†ì—ì„œ ì˜ê°ì„ ì–»ê³ , ëª¸ì„ ì›€ì§ì´ë©° í™œë ¥ì„ ì°¾ëŠ”ë‹¤ëŠ” ê³µí†µì ì´ ìˆëŠ” ê²ƒ ê°™ì•„ìš”. ì •ë§ ê±´ê°•í•˜ê³  ì°½ì˜ì ì¸ ì‚¶ì„ ì¦ê¸°ì‹œëŠ”êµ°ìš”! ì–´ë–¤ ì´ì•¼ê¸°ë“  ë” ìì„¸íˆ ë“¤ë ¤ì£¼ì‹œë©´ ì •ë§ ì¬ë¯¸ìˆì„ ê²ƒ ê°™ì•„ìš”. ì‚¬ì§„ ì°ì€ ì´ì•¼ê¸°ë‚˜ ì„œí•‘ ê²½í—˜ë‹´ì„ ë“¤ë ¤ì£¼ì„¸ìš”!', additional_kwargs={}, response_metadata={})
    ]
}  
```
 
ë˜í•œ DB Browserë¥¼ í†µí•´ chat_history.db íŒŒì¼ì„ ì—´ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì €ì¥ë˜ì–´ìˆë‹¤.

![DBì— ì €ì¥ëœ ëŒ€í™” ë‚´ìš©](image-15.png)
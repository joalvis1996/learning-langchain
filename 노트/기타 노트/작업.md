## Python 프로젝트 실행 방법

프로젝트 루트에서 
```requirements.txt``` 생성

requirements.txt 내용:

```
langchain
langchain_core
langchain_google_genai
```

# 새 가상환경 생성
python -m venv .venv

# 가상환경 활성화 (Windows PowerShell)
.\.venv\Scripts\Activate.ps1

# 모듈 설치
pip install -r .\requirements.txt

--- 
## LangSmith
LangSmith란 LangChain 애플리케이션 전체 실행 과정을 시각화하고 분석할 수 있는 운영 및 디버깅 도구이다. 
즉, 내 Chain이 어떻게 작동하고 있는지를 한 눈에 볼 수 있게해주는 LLM Observability 플랫폼이다. 

## 설정 방법
1. https://www.langchain.com/langsmith/observability 접속 후 회원가입 진행
2. 로그인 후 ```+ API Key``` 버튼 클릭하여 생성
3. 생성된 API Key 복사
 
프로젝트에서 다음을 실행하여 langsmith 설치
```pip install -U langchain langsmith```
 
env에 다음을 추가한다
LANGSMITH_API_KEY=발급받은_API_KEY
LANGSMITH_TRACING_V2=true
LANGSMITH_PROJECT=LangChainTest // 설정한 이름대로 LangSmith에 기록됨
 
이때 LANGSMITH_PROJECT 값은 코드에서 선언만 하면 자동으로 생성된다. 즉, LangSmith 대시보드에서 미리 프로젝트를 만들어 둘 필요가 없다.
 
```LANGSMITH_PROJECT=LangChainTest```로 지정을 해두면 LangChain이 실행될 때 해당 이름으로 로그를 보낸다.
 
 
아래와 같이 env 값을 가져오면
```
import os
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
 
load_dotenv()
apiKey = os.getenv("GOOGLE_API_KEY")
 
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.7,
    google_api_key=apiKey
)
 
prompt = PromptTemplate(
    template="{question}에 대해 한 줄로 설명해줘",
    input_variables={"question"}
)
 
chain = prompt | llm
 
response = chain.invoke({"question": "아스날 역대 감독을 알려줘"})
```
 
아래 이미지처럼 LangSmith 대시보드에 상세 로그가 표시된다 (사용된 토큰 수, latency, 시작 시간 등)

---

## 출력파서 (OutputParser)란?

출력파서(OutputParser)는 LLM의 출력을 구조화하는 데 중요한 컴포넌트. LLM은 기본적으로 문자열을 반환한다. 
이러한 LLM의 출력을 받아 다양한 형식(JSON, 리스트, 딕셔너리 등)으로 변환해주는 것이 출력파서이다. LangChain은 다양한 종류의 출력파서를 제공한다. 

<PydanticOutputParser>
언어 모델의 출력을 더 구조화된 형태로 변환해주는 클래스. 단순 텍스트 형태가 아닌 문자열을 Pydantic 모델 (BaseModel)을 이용해 자동으로 파싱하고 스키마 유효성 검증을 제공하는 파서이다. 

즉, LLM이 "{"name": "홍길동", "age": 30}" 같은 JSON 문자열을 생성하면
→ Info(name="홍길동", age=30) 형태의 타입 안전한 Python 객체로 바꿔줍니다.

[설명]
```
class FootBallPlayerInfo(BaseModel):
    name: str = Field(description="이름")
    birthday: str = Field(description="생년월일")
    club: str = Field(description="소속 팀")
    nationality: str = Field(description="국적")
```

LLM이 만들어야 하는 출력 형태를 정의한 것. 즉, 모델에게 "출력은 반드시 이 4개의 정보로 구선된 JSON 형태여야 해"라고 알려주는 것. 
Pydantic의 BaseModel은 이 데이터 형식을 검증한다 (ex. birthday 데이터가 없는 경우 에러 냄)


```
prompt = PromptTemplate(
    template=(
        "다음 문장을 {format_instructions}에 맞는 JSON으로 변환해줘.\n"
        "{format_instructions}\n\n"
        "문장: {sentence}"
    ),
    input_variables=["sentence"],
    partial_variables={
        "format_instructions": parser.get_format_instructions()
    },
)
```

PromptTemplate에서 input_varibles는 실행 시점에 사용자가 넣을 값을 의미하고, partial_variables는 미리 고정시켜두는 값이다. 
위 코드에서 사용자가 나중에 넘겨줄 문장 sentence("부카요 사카는...")는 chain.invoke로 chain이 실행되는 시점에 값이 채워진다. 
반면에 LLM에게 출력 형식을 알려주는 문구인 format_instructions("JSON output should contain...")은 코드 실행 시점에 미리 값이 채워져있다. 

그래서 PromptTemplate이 완성되면 최종적으로는 이러한 문자열이 LLM에게 전달되고 sentence 값은 런타임에서 주입된다.

```
다음 문장을 JSON output should contain name, birthday, club, nationality 에 맞는 JSON으로 변환해줘.
JSON output should contain name, birthday, club, nationality

문장: 부카요 사카는 잉글랜드 프로 축구 선수로, 현재 잉글랜드 프리미어리그의 아스널 FC에서 활약하고 있으며, ...
``

LangChain의 get_format_instructions는 LLM이 따라야 하는 출력 규칙 설명서를 자동으로 만들어준다. 
특히 PydanticOutputParser는 내부적으로 영어 기반으로 작성된 포맷 지침 템플릿을 사용하기 때문에 실제로 parser.get_format_instructions()을 찍어보면 아래처럼 나온다:

```
The output should be a JSON object with the following keys:
- name: 이름
- birthday: 생년월일
- club: 소속 팀
- nationality: 국적
```



```
chain = prompt | llm | parser
```
'|' 는 LCEL 파이프라인 구조를 활용한 데이터 흐름 연결 연산자인다 (앞 단계의 결과를 다음 단계의 입력으로 전달).

우선 prompt가 입력 데이터를 받아서 LLM에게 보낼 프롬프트 문자열을 생성한다. 
llm은 이 프롬프트 문자열을 받아 Gemini에게 질의 후 응답을 생성한다. 
parser는 이 LLM의 문자열 결과를 받아 Pydantic 객체 구조로 변환한다. 

prompt가 LLM에게 보낼 문장을 완성 -> llm에서 Gemini가 문장을 분석하고 JSON으로 변환 -> praser는 JSON이 올바른지 확인 후 Pydantic 객체로 바꿔 줌.


<CommaSeparatedListOutputParser>
CommaSeparatedListOutputParser는 쉼표로 구분된 LLM의 텍스트 데이터를 Python 리스트 형식으로 변환해주는 클래스이다.

```
parser = CommaSeparatedListOutputParser()

prompt = PromptTemplate(
    template="{topic}에 관련된 용어 5가지. "
             "\n{format_instructions}",
    input_varialbes=["topic"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)
```

get_format_instructions()를 프롬프트에 넣으면 LLM은 아래와 같은 지침을 받게된다. 

```
Your response should be a list of comma-separated items, e.g. "foo, bar, baz"
```

즉, 사용자 입력 (topic)이 들어오면 PromptTempalte에 넣어 프롬프트 문자열을 완성하고, 이걸 LLM에게 전달하여 쉼표로 구분된 문자열을 생성한다. 
그리고 쉼표로 구분된 문자열을 CommaSeparatedListOutputParser를 이용해 리스트로 파싱하는 것. 

----------------------------------------------

<StructuredOutputParser>
StructuredOutputParser는 LLM의 텍스트 데이터를 JSON 형태로 강제하여 결과를 Python dict 형식으로 변환해주는 클래스이다. 

아래와 같이 원하는 출력 형식을 정하고 LLM에게 전달하면 구조화된 데이터로 바꿔주는 역할을 한다. 
```
schemas = [
    ResponseSchema(name="answer", description="사용자의 질문에 대한 답변"),
    ResponseSchema(name="source", description="사용자 질문에 답하기 위해 사용된 출처(웹사이트주소)"),
]
```

PydanticOutputParser와 JSON 형식으로 LLM 출력을 변환하는 것은 같지만 StructuredOutputParser 의 경우 타입 검증이 없다. 반면에 PydanticOutputParser는 스키마에 정의한 필드가 누락된 경우 ValidationError가 발생한다.
또한 PydanticOutputParser는 PlayerInfo 객체를 반환하고 StructuredOutputParser는 단순 dict 형식이다. 


| 비교 항목  | StructuredOutputParser | PydanticOutputParser |
| ------ | ---------------------- | -------------------- |
| 사용 난이도 | 쉬움                     | 조금 복잡                |
| 결과 타입  | dict                   | Pydantic 객체          |
| 타입 검증  | ❌ 없음                   | ✅ 있음                 |
| 필드 정의  | ResponseSchema         | BaseModel            |
| 안정성    | 낮음                     | 높음                   |
| 속도     | 빠름                     | 약간 느림                |
| 추천 사용처 | 빠른 프로토타입, 단순 추출        | 프로덕션, API 응답, 데이터 저장 |
```
----------------------------------------------
<DatetimeOutputParser>
 
DatetimeOutputParser는 LLM이 출력한 문자열을 datetime 형식으로 변환해주는 클래스이다.
원하는 포맷을 설정할 수 있고 타임존 설정도 가능하다. 주로 날짜 비교나 기간 계산 등이 필요한 애플리케이션에 사용 시 유리하다.
 
 
----------------------------------------------
<EnumOutputParser>
 
EnumOutputParser는 LLM의 출력을 미리 정의된 선택지(Enum) 중 하나로 제한하고 싶을 때 사용하는 클래스이다.

----------------------------------------------

<OutputFixingParser>
OutputFixingParser는 출력 파싱 과정에서 발생할 수 있는 오류를 자동으로 수정하는 기능을 제공하는 클래스이다. LLM이 잘못된 형식으로 출력했을 때 자동으로 고쳐주는 파서 래퍼(wrapper)이다.
 
LLM이 생성한 결과가 JSON 또는 특정 스키마에 어긋났을 때 LLM을 다시 호출하여 출력 포맷을 수정한다. 즉, 첫 번째 시도에서 스키마를 준수하지 않은 결과가 나온 경우, OutputFixingParser는 수정을 위해 오류를 수정하는 지시문을 포함한 새로운 요청을 LLM에 제출한다.
 
```
class MovieInfo(BaseModel):
    title: str = Field(description="영화 제목")
    director: str = Field(description="감독 이름")
    releaseYear: int = Field(description="개봉 연도")
 
 
parser = PydanticOutputParser(pydantic_object=MovieInfo)
 
// 잘못된 형식을 일부러 입력
misFormattedResult = "{'title': 'Tom Hanks', 'director': 'Forrest Gump', 'releaseYear': 2025}"
 
// 에러 발생: Invalid json output: {'title': 'Tom Hanks', 'director': 'Forrest Gump', 'releaseYear': 2025}
parser.parse(misFormattedResult)
```
 
위 예제에서 코드 실행 시 BaseModel에서 지정한 스키마 형식에 맞지 않으므로 에러가 발생한다. 하지만 저 PydanticOutputParser를 OutputFixingParser로 감싸면 이를 해결할 수 있다.
 
 
```
parser = PydanticOutputParser(pydantic_object=MovieInfo)
 
// 잘못된 형식을 일부러 입력
misFormattedResult = "{'title': 'Tom Hanks', 'director': 'Forrest Gump', 'releaseYear': 2025}"
 
fixingParser = OutputFixingParser.from_llm(parser=parser, llm=llm)
 
movie = fixingParser.parse(misFormattedResult)
print(movie)
```
 
위와 같이 OutputFixingParser가 잘못된 출력값을 LLM에게 고쳐달라고 요청하여 이를 다시 내부 PydanticOutputParser로 재파싱하여 최종 결과값을 출력한다.
fixingParser가 LLM 요청 시 "이 텍스트를 스키마 형식에 맞는 유효한 JSON을 고쳐줘" 라는 프롬프트를 보내고, 수정 결과를 PydanticOutputParser가 MovieInfo 객체로 반환한 것 이다.
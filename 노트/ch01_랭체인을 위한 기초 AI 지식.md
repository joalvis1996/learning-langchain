## LLM (Large Language Model)

- **텍스트 생성** 전용 AI 모델
- 요약/번역/분류 등의 작업에 활용됨
- 텍스트 입력을 받아 인간과 유사한 텍스트 출력을 **예측**하고 **생성**하는 훈련된 알고리즘
- Large = 훈련에 사용되는 데이턱와 파라미터 수가 크다는 의미 
  - ex. GPT-3 모델은 1750억개의 파라미터 가짐 (45 테라바이트 분량의 데이터를 학습)
- Language Model = **신경망**의 일종으로 영어 등의 언어로 작성된 텍스트를 입력 받아 동일하거나 다른 언어로 작성된 텍스트 결과물을 생성. 
  - 신경망은 뉴런 (수학 함수) 여러 개가 각각 산출한 결과를 상호 연결하고 결합해 최종 결과값을 도출하는 ML 모델
  - 뉴런들을 특정 방식으로 배치 후, 적절한 학습 과정과 데이터를 적용하면 단어와 문장의 의미를 해석하는 모델이 생김. 이 모델은 의미를 해석하고 그럴듯하고 읽기 쉬운 텍스트를 생성
  
## LLM의 기능

아래와 같은 문장이 있을 때 LLM은 주어진 단어들의 발생 확률을 추정한다.

```the capital of England is ___ ``` 

정확히 말하면 토큰을 기준으로 확률을 추정한다. 
- 토큰 = 텍스트의 원자 단위로, 토큰화 기법에 따라 문장을 문자나 서브 워드 등의 원자 단위로 분리함
  - ex. GPT-3.5 의 tokenizer는 ```good morning dearest friend``` 라는 문장을 5개의 토큰을 분리 (공백은 ```_```로 표시)
  - 각 토큰은 고유 ID가 존재

LLM의 핵심인 **트랜스포머 신경망 구조**는 문장 내의 각 단어와 다른 모든 단어의 관계를 고려해 문맥을 파악한ㄷ. 

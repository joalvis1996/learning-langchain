## LLM (Large Language Model)

- **텍스트 생성** 전용 AI 모델
- 요약/번역/분류 등의 작업에 활용됨
- 텍스트 입력을 받아 인간과 유사한 텍스트 출력을 **예측**하고 **생성**하는 훈련된 알고리즘
- Large = 훈련에 사용되는 데이턱와 파라미터 수가 크다는 의미 
  - ex. GPT-3 모델은 1750억개의 파라미터 가짐 (45 테라바이트 분량의 데이터를 학습)
- Language Model = **신경망**의 일종으로 영어 등의 언어로 작성된 텍스트를 입력 받아 동일하거나 다른 언어로 작성된 텍스트 결과물을 생성. 
  - 신경망은 뉴런 (수학 함수) 여러 개가 각각 산출한 결과를 상호 연결하고 결합해 최종 결과값을 도출하는 ML 모델
  - 뉴런들을 특정 방식으로 배치 후, 적절한 학습 과정과 데이터를 적용하면 단어와 문장의 의미를 해석하는 모델을 만들 수 있음. 이 모델은 의미를 해석하고 그럴듯하고 읽기 쉬운 텍스트를 생성
  
## LLM의 기능
아래와 같은 문장이 있을 때 LLM은 주어진 단어들의 발생 확률을 추정한다.

```the capital of England is ___ ``` 

정확히 말하면 토큰을 기준으로 확률을 추정한다. 
- 토큰 = 텍스트의 원자 단위로, 토큰화 기법에 따라 문장을 문자나 서브 워드 등의 원자 단위로 분리함
  - ex. GPT-3.5 의 tokenizer는 ```good morning dearest friend``` 라는 문장을 5개의 토큰을 분리 (공백은 ```_```로 표시)
  - 각 토큰은 고유 ID가 존재

LLM의 핵심인 **트랜스포머 신경망 구조**는 문장 내의 각 단어와 다른 모든 단어의 관계를 고려해 문맥을 파악한다. 

위 문장의 단어들의 순서를 인식해 학습한 데이터에서 **유사한 예시들**을 바탕으로 이어질 단어를 예측함. LLM의 훈련 말뭉치에서는 ```England```가 ```France, China, Japan```과 같은 위치에서 자주 등장함. 반대로 수도를 뜻하는 capital 은 학습 데이터의 여러 문장에서 ```England, France, China```등의 단어와 함께 등장함. 학습 과정 중 이런 형태의 반복은 다음 단어가 ```London``` 이어야 함을 정확히 **예측하는 능력**을 형성함. 

## Pre-trained LLM (기본 LLM)
- 모든 유형의 LLM이 기반으로 삼는 **기본** 유형 LLM 
- **자기 지도 학습**을 통해 인터넷, 도서, 신문, 코드, 영상 등 다양한 출처에서 수집한 방대한 양의 텍스트를 학습함. 
- 특정 업무에 한정되지 않고, 광범위한 주제의 텍스트를 이해하고 생성할 수 있음. 

- 자기 지도 학습 = 라벨이 없는 원본 데이터에서 일부를 가리거나 변형하여 자동으로 정답을 생성해 학습하는 방식이다.
  - 언어의 일반적인 표현 능력을 학습
  - 순서와 규칙을 갖고 있는 언어의 특성상, 다음에 올 단어는 이전 단어들과 강하게 연결되어 있음.
  - 모델에게 ```앞에 나온 단어들을 보고 다음 단어를 맞춰라``` 명령 후, 계속 반복하면 문법적 관계, 맥락 등을 내재화하게 됨.
  - ex. 문장 내 단어를 가리고 맞추기(Masked), 다음 단어 예측.

- 지도 학습 = 입력과 정답(라벨)이 쌍으로 주어진 데이터를 이용해 학습하는 방식이다.
  - 특정 **과제 해결** 능력을 학습 (시제 판단, 감정 분류 등)
  - 사람이 직접 **라벨링**한 데이터를 사용하므로 정확한 과제 수행 능력을 얻을 수 있지만, 라벨링 비용이 크다.
  - ex. 이메일 스팸/정상 판단, 문장과 긍정/부정 감정 분류.

> **결론** 
> 자기 지도 학습 = 언어를 전반적으로 이해할 수 있는 두뇌 만들기. 
> 지도 학습 = 그 두뇌에게 특정 시험(감정 분류, 시제 판별)을 준비시키는 것.

## 기본 LLM & Fine-tuning

### 1. 지시 튜닝
- 사람이 주는 **지시문**(instruction)에 따라 올바른 응답을 생성하도록, ```지시문-응답(instruction-response)``` 쌍으로 기본 LLM을 **추가** 학습시키는 과정.
- 기본 LLM은 ```다음 단어 예측```으로 학습했기 때문에, 질문이나 명령을 받았을 때 항상 자연스럽게 대답하지는 못함. 
  - ex. ```세종 대왕이 맥북으로``` 으로 라는 문장을 입력으로 주었다면 일반적인 Pre-Trained 모델은 꺼리낌 없이 ```조선시대 세종대왕이 맥북으로 보고서를 만들었다``` 정도로 문장을 만들어 줄 것. 맥북 다음에 올 단어로 ```보고서```가 가장 높은 **확률**이었기 때문에 그렇게 생성 한 것.
  - ```김치찌개 끓이는 법을 알려줘``` 라는 지시(instruction)에 대한 응답으로 ```물 몇cc, 돼지고기 몇그람, 두부 반모.. 끓이는 순서는..``` 이런 레시피로 답변(output) 셋을 만들어 학습.
  
> **결론**
기본 LLM: 책을 많이 읽어서 지식은 많지만, 질문하면 딱딱 맞게 대답 못하는 사람
지시 튜닝된 LLM = 질문에 맞게 정확하고 깔끔하게 답변하도록 훈련받은 사람

### 2. 대화 튜닝 
- 사람과의 대화 맥락을 자연스럽게 이어가고, 대화체 답변을 잘 하도록 LLM을 추가 학습하는 과정

아래는 맞긴 하지만 너무 교과서적이고 대화 같지 않음.
```
사용자: 안녕?
모델: 안녕? 안녕은 한국어 인사말이고 영어로는 Hello입니다.
```

- 대화 데이터셋 구성 방식 = 사람이 직접 대화 시나리오를 작성
  ```
  [
    {
      "user": "안녕?",
      "assistant": "안녕하세요! 만나서 반가워요."
    },
    {
      "user": "오늘 날씨 어때?",
      "assistant": "오늘은 맑고 기온도 따뜻해서 산책하기 좋아요."
    }
  ]
  ```
- 채팅 + 역할 부여 형식 = OpenAI/Anthropic 스타일처럼 대화에 역할을 지정
  - 각 메시지에 role(system, user, assistant 등)과 content를 붙여 메타데이터화 
  - 역할(메타데이터) 을 통해 모델이 맥락을 쉽게 이해함.
  - 멀티턴 대화 유지에 특히 효과적.

  ```
  [
    {"role": "system", "content": "너는 친절한 여행 가이드야."},
    {"role": "user", "content": "파리 여행 일정 추천해줘."},
    {"role": "assistant", "content": "파리에서는 에펠탑, 루브르 박물관, 세느강 유람선을 추천드려요."},
    {"role": "user", "content": "맛집도 알려줘."},
    {"role": "assistant", "content": "에스카르고와 크레프가 유명한 현지 식당을 추천합니다."}
  ]
  ```
  - system = 모델의 **기본 성격**이나 **규칙**을 정해주는 역할. ```너는 누구인지, 어떤 톤으로 대답해야 하는지``` 등을 정의 (모델은 이 지시를 대화 내내 지켜야 함)
  - user = 실제 사람(사용자)의 발화. 우리가 입력하는 질문이나 요청이 여기에 해당.
  - assistant = 모델(챗봇)의 **응답**을 의미.학습 시엔 ```이 상황에서 모델이 이렇게 답해야 한다는 예시```로 쓰이고, 추론 시엔 모델이 채워야 할 부분.

> **결론**
기본 LLM: 세상 모든 책을 읽고 지식은 많지만, 질문하면 산만하게 장황하게 대답하는 박학다식한 사람
지시 튜닝된 LLM = 시험 문제에 딱 맞는 답을 하도록 훈련받은 사람
대화 뉴팅된 LLM = 대화 예절과 말투를 배워서, 맥락을 이어가며 자연스럽게 대화하는 친구


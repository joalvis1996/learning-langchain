## LLM (Large Language Model)

- **텍스트 생성** 전용 AI 모델
- 요약/번역/분류 등의 작업에 활용됨
- 텍스트 입력을 받아 인간과 유사한 텍스트 출력을 **예측**하고 **생성**하는 훈련된 알고리즘
- Large = 훈련에 사용되는 데이턱와 파라미터 수가 크다는 의미 
  - ex. GPT-3 모델은 1750억개의 파라미터 가짐 (45 테라바이트 분량의 데이터를 학습)
- Language Model = **신경망**의 일종으로 영어 등의 언어로 작성된 텍스트를 입력 받아 동일하거나 다른 언어로 작성된 텍스트 결과물을 생성. 
  - 신경망은 뉴런 (수학 함수) 여러 개가 각각 산출한 결과를 상호 연결하고 결합해 최종 결과값을 도출하는 ML 모델
  - 뉴런들을 특정 방식으로 배치 후, 적절한 학습 과정과 데이터를 적용하면 단어와 문장의 의미를 해석하는 모델을 만들 수 있음. 이 모델은 의미를 해석하고 그럴듯하고 읽기 쉬운 텍스트를 생성
  
## LLM의 기능
아래와 같은 문장이 있을 때 LLM은 주어진 단어들의 발생 확률을 추정한다.

```the capital of England is ___ ``` 

정확히 말하면 토큰을 기준으로 확률을 추정한다. 
- 토큰 = 텍스트의 원자 단위로, 토큰화 기법에 따라 문장을 문자나 서브 워드 등의 원자 단위로 분리함
  - ex. GPT-3.5 의 tokenizer는 ```good morning dearest friend``` 라는 문장을 5개의 토큰을 분리 (공백은 ```_```로 표시)
  - 각 토큰은 고유 ID가 존재

LLM의 핵심인 **트랜스포머 신경망 구조**는 문장 내의 각 단어와 다른 모든 단어의 관계를 고려해 문맥을 파악한다. 

위 문장의 단어들의 순서를 인식해 학습한 데이터에서 **유사한 예시들**을 바탕으로 이어질 단어를 예측함. LLM의 훈련 말뭉치에서는 ```England```가 ```France, China, Japan```과 같은 위치에서 자주 등장함. 반대로 수도를 뜻하는 capital 은 학습 데이터의 여러 문장에서 ```England, France, China```등의 단어와 함께 등장함. 학습 과정 중 이런 형태의 반복은 다음 단어가 ```London``` 이어야 함을 정확히 **예측하는 능력**을 형성함. 

## Pre-trained LLM (기본 LLM)
- 모든 유형의 LLM이 기반으로 삼는 **기본** 유형 LLM 
- **자기 지도 학습**을 통해 인터넷, 도서, 신문, 코드, 영상 등 다양한 출처에서 수집한 방대한 양의 텍스트를 학습함. 
- 특정 업무에 한정되지 않고, 광범위한 주제의 텍스트를 이해하고 생성할 수 있음. 

- 자기 지도 학습 = 라벨이 없는 원본 데이터에서 일부를 가리거나 변형하여 자동으로 정답을 생성해 학습하는 방식이다.
  - 언어의 일반적인 표현 능력을 학습
  - 순서와 규칙을 갖고 있는 언어의 특성상, 다음에 올 단어는 이전 단어들과 강하게 연결되어 있음.
  - 모델에게 ```앞에 나온 단어들을 보고 다음 단어를 맞춰라``` 명령 후, 계속 반복하면 문법적 관계, 맥락 등을 내재화하게 됨.
  - ex. 문장 내 단어를 가리고 맞추기(Masked), 다음 단어 예측.

- 지도 학습 = 입력과 정답(라벨)이 쌍으로 주어진 데이터를 이용해 학습하는 방식이다.
  - 특정 **과제 해결** 능력을 학습 (시제 판단, 감정 분류 등)
  - 사람이 직접 **라벨링**한 데이터를 사용하므로 정확한 과제 수행 능력을 얻을 수 있지만, 라벨링 비용이 크다.
  - ex. 이메일 스팸/정상 판단, 문장과 긍정/부정 감정 분류.

> **결론** 
> 자기 지도 학습 = 언어를 전반적으로 이해할 수 있는 두뇌 만들기. 
> 지도 학습 = 그 두뇌에게 특정 시험(감정 분류, 시제 판별)을 준비시키는 것.

## 기본 LLM & Fine-tuning

### 1. 지시 튜닝
- 사람이 주는 **지시문**(instruction)에 따라 올바른 응답을 생성하도록, ```지시문-응답(instruction-response)``` 쌍으로 기본 LLM을 **추가** 학습시키는 과정.
- 기본 LLM은 ```다음 단어 예측```으로 학습했기 때문에, 질문이나 명령을 받았을 때 항상 자연스럽게 대답하지는 못함. 
  - ex. ```세종 대왕이 맥북으로``` 으로 라는 문장을 입력으로 주었다면 일반적인 Pre-Trained 모델은 꺼리낌 없이 ```조선시대 세종대왕이 맥북으로 보고서를 만들었다``` 정도로 문장을 만들어 줄 것. 맥북 다음에 올 단어로 ```보고서```가 가장 높은 **확률**이었기 때문에 그렇게 생성 한 것.
  - ```김치찌개 끓이는 법을 알려줘``` 라는 지시(instruction)에 대한 응답으로 ```물 몇cc, 돼지고기 몇그람, 두부 반모.. 끓이는 순서는..``` 이런 레시피로 답변(output) 셋을 만들어 학습.
  
> **결론**
기본 LLM: 책을 많이 읽어서 지식은 많지만, 질문하면 딱딱 맞게 대답 못하는 사람
지시 튜닝된 LLM = 질문에 맞게 정확하고 깔끔하게 답변하도록 훈련받은 사람

### 2. 대화 튜닝 
- 사람과의 대화 맥락을 자연스럽게 이어가고, 대화체 답변을 잘 하도록 LLM을 추가 학습하는 과정
아래는 맞는 내용이긴 하지만 너무 교과서적이고 대화 같지 않음.
```
사용자: 안녕?
모델: 안녕? 안녕은 한국어 인사말이고 영어로는 Hello입니다.
```

- 대화 데이터셋 구성 방식 = 사람이 직접 대화 시나리오를 작성
  ```
  [
    {
      "user": "안녕?",
      "assistant": "안녕하세요! 만나서 반가워요."
    },
    {
      "user": "오늘 날씨 어때?",
      "assistant": "오늘은 맑고 기온도 따뜻해서 산책하기 좋아요."
    }
  ]
  ```
- 역할 부여 형식 = 대화에 역할을 지정
  - 각 메시지에 role(system, user, assistant 등)과 content를 붙여 메타데이터화 
  - 역할(메타데이터) 을 통해 모델이 맥락을 쉽게 이해함.
  - 멀티턴 대화 유지에 특히 효과적.
  - OpenAI/Anthropic 방식

  ```
  [
    {"role": "system", "content": "너는 친절한 여행 가이드야."},
    {"role": "user", "content": "파리 여행 일정 추천해줘."},
    {"role": "assistant", "content": "파리에서는 에펠탑, 루브르 박물관, 세느강 유람선을 추천드려요."},
    {"role": "user", "content": "맛집도 알려줘."},
    {"role": "assistant", "content": "에스카르고와 크레프가 유명한 현지 식당을 추천합니다."}
  ]
  ```
  - system = 모델의 **기본 성격**이나 **규칙**을 정해주는 역할. ```너는 누구인지, 어떤 톤으로 대답해야 하는지``` 등을 정의 (모델은 이 지시를 대화 내내 지켜야 함)
  - user = 실제 사람(사용자)의 발화. 우리가 입력하는 질문이나 요청이 여기에 해당.
  - assistant = 모델(챗봇)의 **응답**을 의미.학습 시엔 ```이 상황에서 모델이 이렇게 답해야 한다는 예시```로 쓰이고, 추론 시엔 모델이 채워야 할 부분.

> **결론**
기본 LLM: 세상 모든 책을 읽고 지식은 많지만, 질문하면 산만하게 장황하게 대답하는 박학다식한 사람
지시 튜닝된 LLM = 시험 문제에 딱 맞는 답을 하도록 훈련받은 사람
대화 뉴팅된 LLM = 대화 예절과 말투를 배워서, 맥락을 이어가며 자연스럽게 대화하는 친구

## 프롬프트 엔지니어링
- 이미 존재하는 LLM을 원하는 작업을 할 수 있도록 **조정**하는 것
 
### 1. 제로샷 프롬프트
- 어떠한 example도 주지 않고 오로지 **지시(instruction)** 만으로 문제를 풀게 하는 방식
 
    ```
    # 단순 지시, 예시 없음
    Explain the offside rule in soccer.
    ```
 
### 2. 사고의 연쇄 (CoT)
- LLM이 **시간을 들여 사고하도록** 프롬프트 앞에 LLM이 답에 도달하는 과정을 설명하도록 지시(instruction)을 삽입하는 방식
- 전반적으로 작업의 성능을 높임
- 다만, 이미지 캡션 생성처럼 사람이 **생각할수록 효율이 떨어지는** 작업에서 사용 시 효율 낮아짐
 
    ```
    # 사고 과정을 단계별로 쓰도록 지시
    Explain the offside rule in soccer.
    Think step by step:
    1. Describe when a player is considered offside.
    2. Explain the role of the ball and the second-last defender.
    3. Summarize the rule in one short sentence.
    ```
 
### 3. 검색 증강 생성 (RAG)
- 관련 있는 **텍스트(켄텍스트)**를 프롬프트에 포함시키는 방식
- 실제 애플리케이션에서는 CoT와 결합해 사용
 
    ```
    # 외부 문서/DB에서 관련 컨텍스트를 포함
    [Context]
    "A player is in an offside position if they are nearer to the opponent’s goal line than both the ball and the second-last opponent, at the moment the ball is played to them.  
    However, being in an offside position is not an offense by itself; the player must also be involved in active play."
 
    [Question]
    What is the offside rule in soccer?
    ```
 
### 4. 툴 호출
- 프롬프트에 미리 LLM이 사용할 수 있는 **외부 함수(툴)**을 불러와서 문제를 풀게 하는 방식
 
    ```
    # 외부 API/툴을 불러 정보를 가져오도록 유도
    You have access to the following tool:
    - get_soccer_rule(rule_name: str): returns details of soccer rules.
 
    User: "What is the offside rule in soccer?"
    ```
 
### 5. 퓨샷 프롬프트
- 단순 지시뿐만 아니라 질문&정답 예제를 제공하여 문제를 푸는 **패턴**을 학습하도록 하는 방식
- 추가적인 훈련 및 파인튜닝을 거치지 않고 새로운 작업을 수행하는 방법을 익히게 함
- 파인튜닝 보다 **유연함**
    - 파인튜닝은 모델 파라미터 자체를 다시 학습시켜야 함, 퓨삿은 단순히 예시 몇 개를 프롬프트에 넣는 것만으로 동작 (코드 수정 불필요)
    - 파인튜닝은 데이터셋이 잘못되면 모델이 영구적으로 편향됨, 퓨삿은 단순히 프롬프트만 바꾸면 돼서 롤백 매우 쉬움 (리스크 낮음)
    - 파인튜닝은 수천~수만 개의 샘플 필요, 퓨삿은 3~10개만으로도 충분 (데이터 요구량 적음)
- 파인튜닝 전에 퓨삿을 먼저 시도하는 이유
    - 시간 및 비용 절약: GPU, 학습, 검증 데이터가 필요한 파인튜닝에 비해 퓨삿은 비용이 0
    - 유연한 반복 실험 가능: ```예시 3개 넣었을 떄 vs 5개 넣었을 때``` 같은 실험을 빠르게 돌릴 수 있음, 파인튜닝은 매번 모델을 다시 학습해야 함
    - 프로토타입에 최적: 아이디어 단계에서 퓨삿으로 빠른 검증, 서비스 단계에서 충분한 데이터 모이면 파인튜닝 고려
- 정적 vs 동적 퓨샷 프롬프팅
    1. 정적 퓨삿 프롬프팅: 항상 고정된 예시를 프롬프트에 포함하는 방식 (모든 query에 동일하게 적용됨)
        - 구현 간단
        - 결과가 일관적/안정적
        - 예시가 너무 일반적이면 특정 질문에는 적합하지 않을 수 있음
        - 새로운 유형의 query에는 대응 어려움
 
        ```
        You are a policy assistant. Answer based on given examples.
 
        Q: "재난적 의료비 지원 조건은?"
        A: "재난적 의료비는 본인부담 상한제를 초과하는 경우 지원 가능."
 
        Q: "외국인도 지원 대상이야?"
        A: "원칙적으로 내국인을 대상으로 하지만 일부 체류 자격자는 예외적으로 가능."
        ```
    2. 동적 퓨삿 프롬프팅: 질문에 따라 적절한 예시를 DB에서 검색 후 프롬프트에 포함시키는 방식
        - 예시가 매번 달라짐
        - 유저 query와 가장 비슷한 예시를 제공 (답변 정확도 향상)
        - 최신 예시를 반영할 수 있음
        - 검색 시스템을 구축해야 함 (벡터 DB, RAG)
        - 응답 속도 느려질 수 있음
        - RAG 구현 방식 중 하나이나 RAG가 더 넓은 개념. RAG는 단순 예시 검색뿐만 아니라 문서 검색, 지식 그래프, API 호출까지 포함.
   
    ```
    # 예시 Q&A를 먼저 제공해 패턴을 학습시킴
    You are a soccer coach. Explain rules simply.
 
    Q: What is the handball rule in soccer?
    A: It is a foul if a player deliberately touches the ball with their hand or arm.
 
    Q: What is the penalty kick rule in soccer?
    A: A penalty is awarded when a foul is committed inside the defending team’s penalty area.
 
    Q: What is the offside rule in soccer?
    A:
    ```